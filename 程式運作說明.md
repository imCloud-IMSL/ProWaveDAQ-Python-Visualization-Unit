# ProWaveDAQ Python 即時資料可視化系統 - 詳細程式運作說明

## 目錄

1. [專案概述](#專案概述)
2. [系統架構](#系統架構)
3. [核心模組詳細說明](#核心模組詳細說明)
4. [資料流程](#資料流程)
5. [Web 介面與 API](#web-介面與-api)
6. [執行緒架構](#執行緒架構)
7. [設定檔說明](#設定檔說明)
8. [檔案結構](#檔案結構)
9. [程式碼詳細解析](#程式碼詳細解析)
10. [運作流程](#運作流程)

---

## 專案概述

### 系統目的

ProWaveDAQ 即時資料可視化系統是一個基於 Python 的振動數據採集與可視化平台，主要功能包括：

1. **從 ProWaveDAQ 設備採集振動數據**：透過 Modbus RTU 協議從硬體設備讀取三通道振動數據
2. **即時資料可視化**：在瀏覽器中即時顯示連續振動曲線圖
3. **自動 CSV 儲存**：根據設定的時間間隔自動分檔儲存資料
4. **Web 介面控制**：提供完整的瀏覽器操作介面，無需終端機操作

### 技術棧

- **後端**：Python 3.9+
- **Web 框架**：Flask 3.1.2+
- **通訊協議**：Modbus RTU（透過 pymodbus 3.11.3+）
- **串列埠通訊**：pyserial 3.5+
- **前端可視化**：Chart.js 3.9.1
- **資料儲存**：CSV 格式

---

## 系統架構

### 整體架構圖

```
┌─────────────────────────────────────────────────────────────┐
│                      Web 瀏覽器（前端）                       │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  index.html: 即時圖表、控制按鈕、狀態顯示              │  │
│  │  config.html: 設定檔編輯介面                          │  │
│  └───────────────────────────────────────────────────────┘  │
└───────────────────────┬─────────────────────────────────────┘
                        │ HTTP/JSON
                        ▼
┌─────────────────────────────────────────────────────────────┐
│                 Flask Web 伺服器 (main.py)                   │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  Flask Thread: 處理 HTTP 請求                          │  │
│  │  - /: 主頁                                             │  │
│  │  - /data: 回傳即時資料                                 │  │
│  │  - /start: 啟動資料收集                                │  │
│  │  - /stop: 停止資料收集                                 │  │
│  │  - /config: 設定檔管理                                 │  │
│  └───────────────────────────────────────────────────────┘  │
└───────────────────────┬─────────────────────────────────────┘
                        │
        ┌───────────────┼───────────────┐
        │               │               │
        ▼               ▼               ▼
┌───────────────┐ ┌───────────────┐ ┌───────────────┐
│  Collection   │ │  Real-time    │ │  CSV Writer   │
│  Thread       │ │  Data Buffer  │ │  Thread       │
│  (資料收集迴圈)│ │  (記憶體變數) │ │  (檔案寫入)   │
└───────┬───────┘ └───────────────┘ └───────────────┘
        │
        ▼
┌─────────────────────────────────────────────────────────────┐
│              ProWaveDAQ 類別 (prowavedaq.py)                 │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  Reading Thread: Modbus RTU 讀取迴圈                  │  │
│  │  - 讀取設備資料                                        │  │
│  │  - 資料轉換（16位元 → 浮點數）                         │  │
│  │  - 放入資料佇列 (queue.Queue)                          │  │
│  └───────────────────────────────────────────────────────┘  │
└───────────────────────┬─────────────────────────────────────┘
                        │ Modbus RTU
                        ▼
┌─────────────────────────────────────────────────────────────┐
│              ProWaveDAQ 硬體設備                              │
│  - 串列埠：/dev/ttyUSB0                                      │
│  - 鮑率：3000000                                            │
│  - 取樣率：7812 Hz                                          │
│  - 從站 ID：1                                               │
└─────────────────────────────────────────────────────────────┘
```

### 模組關係

1. **main.py**（主控制程式）
   - 整合所有模組
   - 提供 Flask Web 服務
   - 管理執行緒和全域狀態

2. **prowavedaq.py**（硬體通訊模組）
   - 處理 Modbus RTU 通訊
   - 讀取設備資料
   - 資料轉換與佇列管理

3. **csv_writer.py**（資料儲存模組）
   - CSV 檔案建立與寫入
   - 自動分檔邏輯

4. **templates/**（前端介面）
   - HTML 模板與 JavaScript
   - Chart.js 圖表顯示

---

## 核心模組詳細說明

### 1. prowavedaq.py - ProWaveDAQ 類別

#### 類別結構

```python
class ProWaveDAQ:
    - client: ModbusSerialClient        # Modbus 連線物件
    - serial_port: str                  # 串列埠路徑
    - baud_rate: int                    # 鮑率
    - sample_rate: int                  # 取樣率 (Hz)
    - slave_id: int                     # Modbus 從站 ID
    - reading: bool                      # 讀取狀態旗標
    - reading_thread: Thread            # 讀取執行緒
    - data_queue: queue.Queue           # 資料佇列（最大 1000 筆）
    - counter: int                       # 讀取計數器
```

#### 主要方法

##### `init_devices(filename: str)`

**功能**：從 INI 設定檔初始化設備並建立 Modbus 連線

**運作流程**：
1. 讀取 `ProWaveDAQ.ini` 設定檔
   - `serialPort`: 串列埠路徑（預設 `/dev/ttyUSB0`）
   - `baudRate`: 鮑率（預設 `3000000`）
   - `sampleRate`: 取樣率（預設 `7812` Hz）
   - `slaveID`: 從站 ID（預設 `1`）

2. 建立 Modbus RTU 連線
   - 使用 `ModbusSerialClient` 建立串列埠連線
   - 設定參數：`parity='N'`, `stopbits=1`, `bytesize=8`, `framer="rtu"`
   - 連線超時設定為 1 秒

3. 讀取晶片 ID（驗證連線）
   - 讀取位址 `0x80` 的 3 個輸入暫存器
   - 顯示晶片 ID 用於驗證

4. 設定取樣率
   - 寫入位址 `0x01`，設定設備取樣率

**錯誤處理**：
- 連線失敗時輸出錯誤訊息並返回
- INI 檔案解析錯誤時使用預設值

##### `start_reading()`

**功能**：啟動背景執行緒開始讀取資料

**運作流程**：
1. 檢查是否已在讀取中（避免重複啟動）
2. 設定 `reading = True`
3. 建立並啟動背景執行緒執行 `_read_loop()`
4. 執行緒設定為 `daemon=True`（主程式結束時自動終止）

##### `_read_loop()`

**功能**：主要的資料讀取迴圈（在獨立執行緒中執行）

**運作流程**：

1. **初始化**
   - 建立資料緩衝區 `vib_data`（最大 41×3 = 123 個資料點）
   - 設定連續錯誤計數器 `consecutive_errors`（最多允許 5 次）

2. **讀取資料長度**
   - 從位址 `0x02` 讀取 1 個輸入暫存器，取得資料長度 `this_len`

3. **主迴圈**（`while self.reading`）：
   
   a. **連線狀態檢查**
      - 檢查 Modbus 連線是否正常
      - 如果連線中斷，嘗試重新連線（最多 5 次）
   
   b. **緩衝區狀態檢查**
      - 如果 `buffer_count == 0`，讀取緩衝區狀態（Address 0x02）
      - 如果緩衝區為空，等待 10ms 後繼續
   
   c. **讀取模式判斷與執行**：
      
      - **Normal Mode**（`buffer_count <= 123`）：
        - 從 Address `0x02` 讀取資料
        - 讀取 `buffer_count + 1` 個暫存器（包含 Header）
        - Header（第一個暫存器）包含剩餘樣本數
        - 實際資料從第二個暫存器開始
        - 最多讀取 123 個樣本
      
      - **Bulk Mode**（`buffer_count > 123`）：
        - 從 Address `0x15` 讀取資料
        - 讀取 `min(buffer_count, 9) + 1` 個暫存器（包含 Header）
        - 最多讀取 9 個樣本（建議的 Bulk 傳輸區塊大小）
        - Header（第一個暫存器）包含剩餘樣本數
   
   d. **資料驗證與轉換**
      - 驗證資料長度是否為 3 的倍數（完整的 XYZ 三軸組）
      - 將 16 位元有符號整數轉換為浮點數
      - 轉換公式：`value = vib_data[i] if vib_data[i] < 32768 else vib_data[i] - 65536`
      - 除以 8192.0 進行正規化：`processed_data.append(value / 8192.0)`
   
   e. **放入佇列**
      - 使用 `data_queue.put_nowait(processed_data)` 放入佇列
      - 如果佇列已滿（10000 筆），移除最舊的資料（FIFO）
      - 更新 `buffer_count` 為 Header 中的剩餘樣本數
   
   f. **錯誤處理**
      - 連續錯誤計數器遞增
      - 如果連續錯誤 ≥ 5 次，停止讀取並跳出迴圈
      - 連線錯誤時嘗試重新連線
      - 資料長度不符合預期時重置 `buffer_count`

4. **例外處理**
   - 捕獲所有例外並輸出錯誤訊息
   - 關鍵錯誤時停止讀取

**資料格式**：
- 輸入：16 位元有符號整數陣列
- 輸出：浮點數陣列（已正規化）

##### `get_data() -> List[float]`

**功能**：非阻塞式取得資料（從佇列取出）

**運作方式**：
- 使用 `queue.get_nowait()` 非阻塞取得資料
- 如果佇列為空，返回空陣列 `[]`
- 避免阻塞主執行緒

##### `stop_reading()`

**功能**：停止讀取並清理資源

**運作流程**：
1. 設定 `reading = False`（停止讀取迴圈）
2. 等待讀取執行緒結束（`join()`）
3. 清空資料佇列
4. 關閉 Modbus 連線

##### `_reconnect() -> bool`

**功能**：重新建立 Modbus 連線

**運作流程**：
1. 關閉舊連線
2. 重新建立 `ModbusSerialClient`
3. 嘗試連線
4. 設定從站 ID
5. 返回連線成功/失敗狀態

---

### 2. csv_writer.py - CSVWriter 類別

#### 類別結構

```python
class CSVWriter:
    - channels: int                    # 通道數量（固定為 3）
    - output_dir: str                   # 輸出目錄路徑
    - label: str                        # 資料標籤
    - file_counter: int                 # 檔案計數器
    - current_file: file                # 當前開啟的檔案物件
    - writer: csv.writer                # CSV 寫入器物件
```

#### 主要方法

##### `__init__(channels, output_dir, label)`

**功能**：初始化 CSV 寫入器

**運作流程**：
1. 儲存參數（通道數、輸出目錄、標籤）
2. 初始化檔案計數器為 1
3. 建立輸出目錄（如果不存在）
4. 建立第一個 CSV 檔案

##### `_create_new_file()`

**功能**：建立新的 CSV 檔案

**運作流程**：
1. 產生檔案名稱：`{timestamp}_{label}_{file_counter:03d}.csv`
   - 時間戳記格式：`YYYYMMDDHHMMSS`
   - 檔案計數器：3 位數，從 001 開始
2. 開啟檔案（UTF-8 編碼）
3. 建立 CSV 寫入器
4. 寫入標題行：`['Timestamp', 'Channel_1', 'Channel_2', 'Channel_3']`
5. 立即寫入磁碟（`flush()`）

**檔案命名範例**：
- `20250106120000_test_001.csv`
- `20250106120000_test_002.csv`

##### `add_data_block(data: List[float])`

**功能**：將資料區塊寫入 CSV 檔案

**運作流程**：
1. 檢查資料是否為空
2. 取得當前時間戳記（ISO 格式）
3. **按通道分組寫入**：
   - 資料格式：`[ch1_val, ch2_val, ch3_val, ch1_val, ch2_val, ch3_val, ...]`
   - 每 3 個資料點為一組（對應 3 個通道）
   - 寫入格式：`[timestamp, channel_1_value, channel_2_value, channel_3_value]`
4. 如果資料不足 3 的倍數，不足的通道填充 0.0
5. 立即寫入磁碟（`flush()`）

**資料寫入範例**：
```csv
Timestamp,Channel_1,Channel_2,Channel_3
2025-01-06T12:00:00.123456,0.123,0.456,0.789
2025-01-06T12:00:00.123489,0.234,0.567,0.890
```

##### `update_filename()`

**功能**：建立新檔案（分檔）

**運作流程**：
1. 關閉當前檔案
2. 檔案計數器遞增
3. 呼叫 `_create_new_file()` 建立新檔案

##### `close()`

**功能**：關閉 CSV 檔案

**運作流程**：
1. 關閉檔案物件
2. 清空檔案和寫入器參考

---

### 3. main.py - Flask Web 伺服器與主控制程式

#### 全域狀態變數

```python
app: Flask                              # Flask 應用程式實例
realtime_data: List[float]              # 即時資料緩衝區（用於前端顯示）
data_lock: threading.Lock              # 資料存取鎖定
is_collecting: bool                     # 資料收集狀態旗標
collection_thread: Thread               # 資料收集執行緒
daq_instance: ProWaveDAQ                # DAQ 實例
csv_writer_instance: CSVWriter         # CSV 寫入器實例
data_counter: int                       # 資料點計數器
target_size: int                        # 每個 CSV 檔案的目標資料點數
current_data_size: int                  # 當前檔案已寫入的資料點數
last_data_request_time: float          # 最後一次 /data API 請求時間（用於追蹤活躍連線）
data_request_lock: threading.Lock      # 請求時間追蹤鎖定
DATA_REQUEST_TIMEOUT: float             # 請求超時時間（5.0 秒）
```

#### 核心函數

##### `update_realtime_data(data: List[float])`

**功能**：更新即時資料緩衝區（供前端顯示），採用智慧緩衝區更新機制

**運作流程**：
1. **檢查活躍連線**
   - 檢查最後一次 `/data` API 請求時間
   - 如果 5 秒內有請求，視為有活躍的前端連線
   
2. **條件更新緩衝區**
   - **如果有活躍連線**：
     - 取得資料鎖定（`data_lock`）
     - 將新資料附加到 `realtime_data`
     - **記憶體管理**：如果資料超過 10000 個點，只保留最近 10000 個點（避免記憶體過載）
   - **如果無活躍連線**：
     - 跳過緩衝區更新（節省 CPU 和記憶體）
     - 但 CSV 寫入和計數器仍正常運作
   
3. **更新計數器**
   - 無論是否有活躍連線，始終更新 `data_counter`（用於狀態顯示）

**設計理由**：
- 當使用者離開網頁時，停止更新即時資料緩衝區，節省資源
- CSV 寫入不受影響，確保資料不遺失
- 使用者回到網頁時，前端會自動恢復狀態並開始更新

##### `get_realtime_data() -> List[float]`

**功能**：取得即時資料的副本（供前端 API 使用）

**運作流程**：
1. 取得資料鎖定
2. 返回資料的副本（避免前端修改原始資料）

#### Flask 路由

##### `@app.route('/')` - 主頁

**功能**：顯示主頁面（包含設定表單、Label 輸入、開始/停止按鈕、即時圖表）

**回應**：渲染 `templates/index.html` 模板

##### `@app.route('/data')` - 取得即時資料

**功能**：回傳目前最新資料給前端（JSON 格式），並追蹤活躍連線狀態

**回應格式**：
```json
{
  "success": true,
  "data": [0.123, 0.456, 0.789, ...],
  "counter": 12345
}
```

**運作流程**：
1. **更新請求時間**
   - 更新 `last_data_request_time` 為當前時間
   - 表示有活躍的前端連線（用於智慧緩衝區更新）
   
2. 取得即時資料副本
3. 取得資料點計數器
4. 返回 JSON 回應

**設計理由**：
- 追蹤前端連線狀態，優化資源使用
- 無連線時不更新緩衝區，節省 CPU 和記憶體

##### `@app.route('/status')` - 檢查資料收集狀態

**功能**：檢查資料收集狀態（用於前端狀態恢復）

**回應格式**：
```json
{
  "success": true,
  "is_collecting": true,
  "counter": 12345
}
```

**運作流程**：
1. 取得 `is_collecting` 狀態
2. 取得資料點計數器
3. 返回 JSON 回應

**使用場景**：
- 前端頁面載入時檢查後端狀態
- 如果後端正在收集資料，前端自動恢復狀態並開始更新圖表

##### `@app.route('/config', methods=['GET', 'POST'])` - 設定檔管理

**GET 請求**：
- 讀取 `API/ProWaveDAQ.ini` 和 `API/Master.ini`
- 渲染 `templates/config.html`，顯示設定檔內容供編輯

**POST 請求**：
- 接收表單資料（兩個設定檔的內容）
- 寫入 `API/ProWaveDAQ.ini` 和 `API/Master.ini`
- 返回成功/失敗 JSON 回應

**錯誤處理**：
- 檔案讀取失敗時使用預設內容
- 寫入失敗時返回錯誤訊息

##### `@app.route('/files_page')` - 檔案瀏覽頁面

**功能**：顯示檔案瀏覽頁面

**回應**：渲染 `templates/files.html` 模板

##### `@app.route('/files')` - 列出檔案和資料夾

**功能**：列出 `output/ProWaveDAQ/` 目錄中的檔案和資料夾

**查詢參數**：
- `path` (可選)：要瀏覽的子目錄路徑

**回應格式**：
```json
{
  "success": true,
  "items": [
    {
      "name": "20240101120000_test_001",
      "type": "directory",
      "path": "20240101120000_test_001"
    },
    {
      "name": "data.csv",
      "type": "file",
      "path": "data.csv",
      "size": 1024
    }
  ],
  "current_path": ""
}
```

**運作流程**：
1. 取得路徑參數（如果提供）
2. 安全檢查：確保路徑在 `output/ProWaveDAQ/` 目錄內
3. 列出目錄內容
4. 區分資料夾和檔案
5. 返回 JSON 回應

**安全機制**：
- 路徑標準化檢查，防止目錄遍歷攻擊
- 只允許存取 `output/ProWaveDAQ/` 目錄下的檔案

##### `@app.route('/download')` - 下載檔案

**功能**：下載指定的 CSV 檔案

**查詢參數**：
- `path` (必需)：要下載的檔案路徑

**運作流程**：
1. 取得路徑參數
2. 安全檢查：確保路徑在 `output/ProWaveDAQ/` 目錄內
3. 驗證檔案存在且為檔案（非資料夾）
4. 使用 `send_from_directory()` 發送檔案

**安全機制**：
- 路徑標準化檢查，防止目錄遍歷攻擊
- 只允許下載 `output/ProWaveDAQ/` 目錄下的檔案

##### `@app.route('/start', methods=['POST'])` - 啟動資料收集

**功能**：啟動資料收集、CSV 寫入和即時顯示

**請求格式**：
```json
{
  "label": "test_001"
}
```

**運作流程**：

1. **檢查狀態**
   - 如果已在收集，返回錯誤

2. **驗證 Label**
   - 如果 Label 為空，返回錯誤

3. **重置狀態**
   - 清空即時資料緩衝區
   - 重置資料點計數器
   - 重置當前資料大小
   - 重置請求時間追蹤（`last_data_request_time = 0`）

4. **載入設定檔**
   - 讀取 `API/Master.ini`
   - 取得 `SaveUnit.second`（分檔時間間隔，預設 5 秒）

5. **初始化 DAQ**
   - 建立 `ProWaveDAQ` 實例
   - 從 `API/ProWaveDAQ.ini` 初始化設備
   - 取得取樣率（預設 7812 Hz）
   - 通道數固定為 3

6. **計算目標大小**
   - `target_size = second × sample_rate × channels`
   - 範例：5 秒 × 7812 Hz × 3 通道 = 117,180 個資料點

7. **建立輸出目錄**
   - 路徑：`output/ProWaveDAQ/{timestamp}_{label}/`
   - 時間戳記格式：`YYYYMMDDHHMMSS`

8. **初始化 CSV Writer**
   - 建立 `CSVWriter` 實例

9. **啟動資料收集執行緒**
   - 設定 `is_collecting = True`
   - 建立並啟動 `collection_loop` 執行緒（daemon=True）

10. **啟動 DAQ 讀取**
    - 呼叫 `daq_instance.start_reading()`

11. **返回成功回應**
    - 包含取樣率和分檔間隔資訊

**回應格式**：
```json
{
  "success": true,
  "message": "資料收集已啟動 (取樣率: 7812 Hz, 分檔間隔: 5 秒)"
}
```

##### `@app.route('/stop', methods=['POST'])` - 停止資料收集

**功能**：停止所有執行緒並安全關閉

**運作流程**：
1. 檢查是否在收集中（如果未在收集，返回錯誤）
2. 設定 `is_collecting = False`（停止收集迴圈）
3. 停止 DAQ 讀取（`daq_instance.stop_reading()`）
4. 關閉 CSV Writer（`csv_writer_instance.close()`）
5. 返回成功回應

##### `collection_loop()` - 資料收集主迴圈

**功能**：在獨立執行緒中執行，持續處理資料並分發到即時顯示和 CSV 儲存

**運作流程**：

1. **主迴圈**（`while is_collecting`）：
   
   a. **從 DAQ 取得資料**
      - 呼叫 `daq_instance.get_data()`（非阻塞）
      - 如果沒有資料，返回空陣列
   
   b. **持續處理佇列中的所有資料**
      - `while data and len(data) > 0`：
      
      i. **更新即時顯示**
         - 呼叫 `update_realtime_data(data)`
         - 資料會出現在前端圖表
      
      ii. **寫入 CSV（分檔邏輯）**
          
          - **累積資料大小**：`current_data_size += len(data)`
          
          - **如果 `current_data_size < target_size`**：
            - 資料還未達到分檔門檻，直接寫入當前檔案
            - `csv_writer_instance.add_data_block(data)`
          
          - **如果 `current_data_size >= target_size`**：
            - 需要分檔處理
            - 計算剩餘空間：`empty_space = target_size - (current_data_size - len(data))`
            - **分批處理**（`while current_data_size >= target_size`）：
              - 取出一個完整批次：`batch = data[:empty_space]`
              - 寫入當前檔案
              - 更新檔案名稱（建立新檔案）：`csv_writer_instance.update_filename()`
              - 減少累積大小：`current_data_size -= target_size`
            - **處理剩餘資料**：
              - 如果還有剩餘資料（`pending = len(data) - empty_space`）：
                - 寫入新檔案：`csv_writer_instance.add_data_block(remaining_data)`
                - 更新累積大小：`current_data_size = pending`
              - 否則：`current_data_size = 0`
      
      iii. **繼續從佇列取得下一筆資料**
          - `data = daq_instance.get_data()`
   
   c. **短暫休息**
      - `time.sleep(0.01)`（10ms），避免 CPU 過載

2. **錯誤處理**：
   - 捕獲所有例外並輸出錯誤訊息
   - 發生錯誤時等待 0.1 秒後繼續

**分檔邏輯範例**：

假設 `target_size = 117180`（5 秒 × 7812 Hz × 3 通道）

- **情況 1**：`current_data_size = 100000`，新資料 `len(data) = 10000`
  - 總計：110000 < 117180
  - 直接寫入，`current_data_size = 110000`

- **情況 2**：`current_data_size = 110000`，新資料 `len(data) = 20000`
  - 總計：130000 ≥ 117180
  - 第一個批次：`empty_space = 117180 - 110000 = 7180`
  - 寫入 7180 個資料點，更新檔案，`current_data_size = 0`
  - 剩餘：`20000 - 7180 = 12820`
  - 寫入剩餘資料到新檔案，`current_data_size = 12820`

##### `run_flask_server()` - Flask 伺服器執行函數

**功能**：在獨立執行緒中執行 Flask 伺服器

**設定**：
- 主機：`0.0.0.0`（監聽所有網路介面）
- 埠：`8080`
- 除錯模式：`False`
- 重新載入器：`False`（避免與執行緒衝突）

##### `main()` - 主函數

**功能**：程式入口點

**運作流程**：
1. 輸出啟動訊息
2. 在背景執行緒中啟動 Flask 伺服器（daemon=True）
3. 主執行緒進入無限迴圈（`while True: time.sleep(1)`）
4. 等待使用者按 Ctrl+C 中斷
5. **清理資源**：
   - 如果正在收集，停止收集
   - 停止 DAQ
   - 關閉 CSV Writer
6. 輸出關閉訊息

---

## 資料流程

### 完整資料流程圖

```
ProWaveDAQ 設備
    │
    │ Modbus RTU 通訊
    │ (串列埠: /dev/ttyUSB0, 鮑率: 3000000)
    ▼
prowavedaq.py::ProWaveDAQ
    │
    │ _read_loop() 執行緒
    │ - 讀取位址 0x02 的資料長度
    │ - 根據長度讀取資料暫存器
    │ - 16 位元整數 → 浮點數轉換（÷8192.0）
    │
    ▼
queue.Queue (最大 1000 筆)
    │
    │ get_data() 非阻塞取得
    ▼
main.py::collection_loop() 執行緒
    │
    ├─→ update_realtime_data()
    │   │
    │   ▼
    │   realtime_data (List[float], 最多 10000 點)
    │   │
    │   ▼
    │   Flask /data API
    │   │
    │   ▼
    │   前端 Chart.js (每 200ms 更新)
    │
    ├─→ csv_writer.add_data_block()
    │       │
    │       ▼
    │   分檔邏輯判斷
    │       │
    │       ├─→ current_data_size < target_size
    │       │   └─→ 直接寫入當前檔案
    │       │
    │       └─→ current_data_size >= target_size
    │           ├─→ 寫入完整批次
    │           ├─→ update_filename() (建立新檔案)
    │           └─→ 處理剩餘資料
    │               │
    │               ▼
    │           CSV 檔案
    │           output/ProWaveDAQ/{timestamp}_{label}/{timestamp}_{label}_{001-999}.csv
    │
    └─→ SQL Uploader（如果啟用）
            │
            ▼
        寫入暫存 CSV 檔案
            │
            ▼
        .sql_temp/{timestamp}_sql_temp.csv
            │
            ▼
        定時上傳執行緒（每 sql_upload_interval 秒）
            │
            ├─→ 讀取暫存檔案
            ├─→ 批次上傳 (executemany)
            ├─→ 重試機制 (最多 3 次)
            ├─→ 失敗保留 (暫存檔案不刪除)
            ├─→ 成功後刪除暫存檔案
            └─→ 建立新暫存檔案
                │
                ▼
            MariaDB/MySQL 資料庫
            vibration_data 資料表（動態建立，表名與 CSV 檔名對應）
```

### 資料格式轉換

1. **硬體 → ProWaveDAQ**
   - 輸入：16 位元有符號整數（0-65535）
   - 轉換：`value = (value < 32768) ? value : value - 65536`
   - 正規化：`float_value = value / 8192.0`
   - 輸出：浮點數陣列

2. **ProWaveDAQ → 即時顯示**
   - 格式：`[ch1, ch2, ch3, ch1, ch2, ch3, ...]`
   - 前端按每 3 個一組分離通道

3. **ProWaveDAQ → CSV**
   - 格式：`[ch1, ch2, ch3, ch1, ch2, ch3, ...]`
   - CSV 寫入器按每 3 個一組寫入一行
   - CSV 格式：`Timestamp,Channel_1,Channel_2,Channel_3`

### 資料量計算

**每秒資料量**：
- 取樣率：7812 Hz
- 通道數：3
- **每秒資料點數**：7812 × 3 = 23,436 個資料點

**每個 CSV 檔案資料量**（預設 5 秒）：
- **資料點數**：7812 × 3 × 5 = 117,180 個資料點
- **檔案大小**（估算）：約 3-5 MB（取決於時間戳記長度）

**記憶體使用**：
- 即時資料緩衝區：最多 10000 個點（約 80 KB）
- DAQ 資料佇列：最多 1000 筆（每筆約 123 個點，約 1 MB）

---

## Web 介面與 API

### 前端頁面

#### index.html - 主頁面

**功能**：
- 顯示即時資料曲線圖
- 提供 Label 輸入欄位
- 開始/停止按鈕
- 狀態顯示（資料點數、收集狀態）

**JavaScript 功能**：

1. **Chart.js 初始化**
   - 建立 3 個資料集（通道 1、2、3）
   - 設定為折線圖，無動畫（`duration: 0`）
   - Y 軸不從零開始（`beginAtZero: false`）
   - 不顯示 X 軸標籤

2. **updateChart()** - 更新圖表
   - 每 200ms 呼叫一次（`setInterval(updateChart, 200)`）
   - 從 `/data` API 取得資料
   - 將資料按通道分組（每 3 個一組）
   - 更新圖表資料
   - 限制最多顯示 5000 個資料點（保持效能）

3. **startCollection()** - 開始收集
   - 驗證 Label 是否輸入
   - 發送 POST 請求到 `/start`
   - 啟動圖表更新定時器
   - 更新 UI 狀態（禁用開始按鈕，啟用停止按鈕）

4. **stopCollection()** - 停止收集
   - 發送 POST 請求到 `/stop`
   - 停止圖表更新定時器
   - 更新 UI 狀態

#### config.html - 設定檔編輯頁面

**功能**：
- 顯示兩個設定檔的內容（文字區域）
- 提供儲存按鈕

**JavaScript 功能**：
- `saveConfig()` - 發送 POST 請求儲存設定檔

#### files.html - 檔案瀏覽頁面

**功能**：
- 顯示 `output/ProWaveDAQ/` 目錄中的檔案和資料夾列表
- 支援資料夾導航
- 支援檔案下載

**JavaScript 功能**：

1. **loadFiles(path)** - 載入檔案列表
   - 呼叫 `/files` API 取得目錄內容
   - 顯示檔案和資料夾列表

2. **displayFiles(items, path)** - 顯示檔案列表
   - 區分資料夾（📁）和檔案（📄）
   - 顯示檔案大小（自動格式化）
   - 為資料夾提供「進入」按鈕
   - 為檔案提供「下載」按鈕

3. **updateBreadcrumb(path)** - 更新麵包屑導航
   - 顯示當前路徑
   - 支援點擊返回上層目錄

4. **navigateTo(path)** - 導航到指定路徑
   - 載入指定目錄的內容

5. **downloadFile(path)** - 下載檔案
   - 開啟 `/download` API 下載檔案

**檔案大小格式化**：
- 自動將位元組轉換為 B、KB、MB、GB

#### index.html - 主頁面（更新）

**新增功能**：

1. **checkAndRestoreStatus()** - 檢查並恢復狀態
   - 頁面載入時呼叫 `/status` API
   - 如果後端正在收集資料，自動恢復前端狀態：
     - 啟用停止按鈕
     - 禁用開始按鈕和 Label 輸入
     - 開始更新圖表
     - 更新狀態顯示

**設計理由**：
- 解決「讀取中進入 config 頁面再回到主畫面會卡狀態」的問題
- 確保前端狀態與後端狀態同步

### API 端點

| 路由 | 方法 | 功能 | 請求格式 | 回應格式 |
|------|------|------|----------|----------|
| `/` | GET | 主頁 | - | HTML |
| `/data` | GET | 取得即時資料 | - | JSON |
| `/status` | GET | 檢查資料收集狀態 | - | JSON |
| `/config` | GET | 顯示設定檔編輯頁 | - | HTML |
| `/config` | POST | 儲存設定檔 | FormData | JSON |
| `/start` | POST | 啟動資料收集 | JSON | JSON |
| `/stop` | POST | 停止資料收集 | - | JSON |
| `/files_page` | GET | 檔案瀏覽頁面 | - | HTML |
| `/files` | GET | 列出檔案和資料夾 | `?path=<路徑>` | JSON |
| `/download` | GET | 下載檔案 | `?path=<路徑>` | 檔案下載 |

---

## 執行緒架構

### 執行緒列表

| 執行緒 | 功能 | 類型 | 狀態管理 |
|--------|------|------|----------|
| **主執行緒** | 控制流程、等待中斷 | 主執行緒 | - |
| **Flask Thread** | 處理 HTTP 請求 | daemon=True | 主程式結束時自動終止 |
| **Reading Thread** (ProWaveDAQ) | Modbus 資料讀取迴圈 | daemon=True | `reading` 旗標 |
| **Collection Thread** (main.py) | 資料處理與分發 | daemon=True | `is_collecting` 旗標 |

### 執行緒同步

1. **資料鎖定** (`data_lock`)
   - 保護 `realtime_data` 和 `data_counter`
   - 使用 `threading.Lock()` 確保執行緒安全

2. **佇列同步** (`data_queue`)
   - 使用 `queue.Queue`（執行緒安全）
   - 最大容量 1000 筆，避免記憶體過載

3. **請求時間追蹤鎖定** (`data_request_lock`)
   - 保護 `last_data_request_time` 變數
   - 用於追蹤活躍的前端連線

4. **狀態旗標**
   - `is_collecting`: 控制收集迴圈
   - `reading`: 控制讀取迴圈

### 執行緒生命週期

```
啟動階段：
1. main() 啟動
2. Flask Thread 啟動（背景）
3. 主執行緒進入等待迴圈

資料收集階段（/start）：
1. 初始化 DAQ 和 CSV Writer
2. Collection Thread 啟動
3. DAQ Reading Thread 啟動
4. 三個執行緒並行運作

停止階段（/stop 或 Ctrl+C）：
1. 設定 is_collecting = False
2. Collection Thread 結束
3. 設定 reading = False
4. DAQ Reading Thread 結束
5. 關閉 CSV Writer
6. 關閉 Modbus 連線
```

---

## 設定檔說明

### API/ProWaveDAQ.ini

**格式**：INI 檔案

**區段**：`[ProWaveDAQ]`

**參數**：

| 參數 | 說明 | 預設值 | 範例 |
|------|------|--------|------|
| `serialPort` | 串列埠路徑 | `/dev/ttyUSB0` | `/dev/ttyUSB0` |
| `baudRate` | 鮑率（bps） | `3000000` | `3000000` |
| `sampleRate` | 取樣率（Hz） | `7812` | `7812` |
| `slaveID` | Modbus 從站 ID | `1` | `1` |

**範例**：
```ini
[ProWaveDAQ]
serialPort = /dev/ttyUSB0
baudRate = 3000000
sampleRate = 7812
slaveID = 1
```

**注意事項**：
- 串列埠路徑需根據實際設備調整
- 鮑率和取樣率需與硬體設備匹配
- 從站 ID 需與設備設定一致

### API/Master.ini

**格式**：INI 檔案

**區段**：`[SaveUnit]`

**參數**：

| 參數 | 說明 | 預設值 | 範例 |
|------|------|--------|------|
| `second` | 每個 CSV 檔案的資料時間長度（秒） | `5` | `1800` |

**範例**：
```ini
[SaveUnit]
second = 1800
```

**分檔邏輯**：
- 每個 CSV 檔案包含的資料點數 = `second × sampleRate × channels`
- 例如：1800 秒 × 7812 Hz × 3 通道 = 42,184,800 個資料點
- 系統會自動計算並在達到目標大小時建立新檔案

---

## 檔案結構

### 專案目錄結構

```
ProWaveDAQ_Python_Visualization_Unit/
│
├── API/                              # 設定檔目錄
│   ├── ProWaveDAQ.ini                # ProWaveDAQ 設備設定檔
│   └── Master.ini                    # 儲存設定檔
│
├── templates/                         # HTML 模板目錄
│   ├── index.html                    # 主頁面（即時圖表、控制按鈕）
│   ├── config.html                   # 設定檔編輯頁面
│   └── files.html                    # 檔案瀏覽頁面
│
├── output/                            # 輸出目錄（自動建立）
│   └── ProWaveDAQ/                   # CSV 檔案輸出目錄
│       └── {timestamp}_{label}/      # 每次收集的資料夾
│           ├── {timestamp}_{label}_001.csv
│           ├── {timestamp}_{label}_002.csv
│           ├── ...
│           └── .sql_temp/            # SQL 暫存檔案目錄（如果啟用 SQL）
│               └── {timestamp}_sql_temp.csv
│
├── prowavedaq.py                     # ProWaveDAQ 核心模組（Modbus 通訊）
├── csv_writer.py                     # CSV 寫入器模組
├── main.py                           # 主控制程式（Flask Web 伺服器）
├── requirements.txt                  # Python 依賴套件列表
├── deploy.sh                         # 自動部署腳本
├── run.sh                            # 啟動腳本
├── README.md                         # 使用說明文件
└── 程式運作說明.md                   # 本文件（詳細程式運作說明）
```

### 檔案說明

| 檔案 | 說明 | 行數 | 主要功能 |
|------|------|------|----------|
| `main.py` | 主控制程式 | 434 | Flask Web 伺服器、執行緒管理、資料收集迴圈、檔案瀏覽 API |
| `prowavedaq.py` | 硬體通訊模組 | 408 | Modbus RTU 通訊、資料讀取、資料轉換 |
| `csv_writer.py` | CSV 寫入器 | 110 | CSV 檔案建立、資料寫入、分檔邏輯 |
| `templates/index.html` | 主頁面 | 405 | 即時圖表、控制介面、JavaScript 邏輯、狀態恢復 |
| `templates/config.html` | 設定檔編輯頁 | 140 | 設定檔編輯介面 |
| `templates/files.html` | 檔案瀏覽頁 | 285 | 檔案列表、資料夾導航、檔案下載 |
| `requirements.txt` | 依賴套件 | 32 | Python 套件版本列表 |
| `deploy.sh` | 部署腳本 | 191 | 自動安裝依賴、設定權限 |
| `run.sh` | 啟動腳本 | 5 | 啟動虛擬環境並執行主程式 |

---

## 程式碼詳細解析

### 關鍵程式碼片段

#### 1. 資料讀取邏輯（prowavedaq.py）

```python
# 讀取模式判斷
if self.buffer_count <= self.BULK_TRIGGER_SIZE:
    # Normal Mode: 從 Address 0x02 讀取
    collected_data, remaining = self._read_normal_data(samples_to_read)
else:
    # Bulk Mode: 從 Address 0x15 讀取（最多 9 個樣本）
    collected_data, remaining = self._read_bulk_data(samples_to_read)

# 讀取方法（包含 Header）
def _read_registers_with_header(self, address, count, mode_name):
    read_count = count + 1  # Header + 資料
    result = self.client.read_input_registers(address=address, count=read_count)
    raw_data = result.registers
    payload_data = raw_data[1:]  # 實際資料（不含 Header）
    remaining_samples = raw_data[0]  # 剩餘樣本數（從 Header 取得）
    return payload_data, remaining_samples
```

**設計理由**：
- 根據緩衝區狀態自動切換 Normal Mode 和 Bulk Mode，優化讀取效率
- FIFO buffer size(0x02) 連同資料一起讀出，確保資料一致性
- Normal Mode：適合資料量較小的情況（≤ 123 個樣本）
- Bulk Mode：適合資料量較大的情況（> 123 個樣本），使用專用的 Bulk 地址

#### 2. 資料轉換邏輯（prowavedaq.py）

```python
# 16 位元有符號整數轉換
value = vib_data[i] if vib_data[i] < 32768 else vib_data[i] - 65536
processed_data.append(value / 8192.0)
```

**轉換說明**：
- 16 位元無符號整數範圍：0-65535
- 有符號整數範圍：-32768 到 32767
- 轉換規則：≥32768 的視為負數（減去 65536）
- 正規化：除以 8192.0（設備特定的轉換係數）

#### 3. 分檔邏輯（main.py）

```python
# 分檔處理
if current_data_size < target_size:
    # 直接寫入
    csv_writer_instance.add_data_block(data)
else:
    # 需要分檔
    empty_space = target_size - (current_data_size - data_actual_size)
    while current_data_size >= target_size:
        batch = data[:empty_space]
        csv_writer_instance.add_data_block(batch)
        csv_writer_instance.update_filename()
        current_data_size -= target_size
    # 處理剩餘資料
    if pending:
        remaining_data = data[empty_space:]
        csv_writer_instance.add_data_block(remaining_data)
        current_data_size = pending
```

**設計理由**：
- 確保每個 CSV 檔案包含精確的資料量
- 處理跨檔案的資料邊界
- 避免資料遺失或重複

#### 4. 記憶體管理與智慧緩衝區更新（main.py）

```python
# 檢查是否有活躍的前端連線
with data_request_lock:
    has_active_connection = (time.time() - last_data_request_time) < DATA_REQUEST_TIMEOUT

# 只有在有活躍連線時才更新即時資料緩衝區
with data_lock:
    if has_active_connection:
        realtime_data.extend(data)
        # 限制記憶體使用，保留最近 10000 個資料點
        if len(realtime_data) > 10000:
            realtime_data = realtime_data[-10000:]
    data_counter += len(data)  # 計數器始終更新
```

**設計理由**：
- 避免記憶體無限增長
- 保留最近 10000 個資料點供顯示
- 前端也限制顯示 5000 個點，保持效能
- **智慧優化**：無活躍連線時不更新緩衝區，節省 CPU 和記憶體
- CSV 寫入不受影響，確保資料不遺失

#### 5. 佇列管理（prowavedaq.py）

```python
# 佇列滿時處理
try:
    self.data_queue.put_nowait(processed_data)
except queue.Full:
    # 移除最舊的資料
    try:
        self.data_queue.get_nowait()
        self.data_queue.put_nowait(processed_data)
    except queue.Empty:
        pass
```

**設計理由**：
- 避免佇列阻塞
- 資料過快時，丟棄最舊的資料（FIFO）
- 確保最新資料優先處理

---

## 運作流程

### 系統啟動流程

```
1. 執行 main.py
   │
   ├─→ 建立 Flask 應用程式
   │
   ├─→ 初始化全域狀態變數
   │   - realtime_data = []
   │   - is_collecting = False
   │   - data_counter = 0
   │
   ├─→ 啟動 Flask Thread（背景）
   │   - 監聽 0.0.0.0:8080
   │   - 處理 HTTP 請求
   │
   └─→ 主執行緒進入等待迴圈
       - while True: time.sleep(1)
       - 等待 Ctrl+C 中斷
```

### 資料收集啟動流程（使用者點擊「開始讀取」）

```
1. 前端發送 POST /start
   │
   ├─→ 驗證 Label
   │
   ├─→ 重置狀態
   │   - 清空 realtime_data
   │   - 重置計數器
   │
   ├─→ 載入設定檔
   │   - 讀取 Master.ini（分檔間隔）
   │   - 讀取 ProWaveDAQ.ini（設備設定）
   │
   ├─→ 初始化 DAQ
   │   - 建立 ProWaveDAQ 實例
   │   - 建立 Modbus 連線
   │   - 設定取樣率
   │
   ├─→ 計算目標大小
   │   - target_size = second × sample_rate × channels
   │
   ├─→ 建立輸出目錄
   │   - output/ProWaveDAQ/{timestamp}_{label}/
   │
   ├─→ 初始化 CSV Writer
   │   - 建立第一個 CSV 檔案
   │
   ├─→ 啟動 Collection Thread
   │   - is_collecting = True
   │   - collection_loop() 開始執行
   │
   ├─→ 啟動 DAQ Reading Thread
   │   - daq_instance.start_reading()
   │   - _read_loop() 開始執行
   │
   └─→ 返回成功回應
       - 前端收到回應，開始更新圖表
```

### 資料收集運作流程（持續執行）

```
DAQ Reading Thread (_read_loop):
├─→ 讀取資料長度（位址 0x02）
├─→ 根據長度讀取資料
├─→ 轉換資料格式（16位元 → 浮點數）
├─→ 放入資料佇列
└─→ 重複執行

Collection Thread (collection_loop):
├─→ 從佇列取得資料
├─→ 更新即時資料緩衝區（供前端顯示）
├─→ 寫入 CSV（包含分檔邏輯）
└─→ 重複執行

Flask Thread:
├─→ 處理 HTTP 請求
├─→ /data: 返回即時資料
├─→ 其他路由: 處理對應功能
└─→ 持續運作

前端 JavaScript:
├─→ 每 200ms 呼叫 /data API
├─→ 更新 Chart.js 圖表
└─→ 顯示狀態資訊
```

### 資料收集停止流程（使用者點擊「停止讀取」）

```
1. 前端發送 POST /stop
   │
   ├─→ 設定 is_collecting = False
   │   - Collection Thread 結束迴圈
   │
   ├─→ 停止 DAQ 讀取
   │   - daq_instance.stop_reading()
   │   - 設定 reading = False
   │   - Reading Thread 結束迴圈
   │   - 關閉 Modbus 連線
   │
   ├─→ 關閉 CSV Writer
   │   - csv_writer_instance.close()
   │   - 關閉當前檔案
   │
   └─→ 返回成功回應
       - 前端停止圖表更新
       - 更新 UI 狀態
```

### 系統關閉流程（Ctrl+C）

```
1. 使用者按 Ctrl+C
   │
   ├─→ 捕獲 KeyboardInterrupt
   │
   ├─→ 檢查是否在收集中
   │   │
   │   ├─→ 如果是：執行停止流程
   │   │   - is_collecting = False
   │   │   - 停止 DAQ
   │   │   - 關閉 CSV Writer
   │   │
   │   └─→ 如果不是：直接關閉
   │
   └─→ 輸出關閉訊息
       - Flask Thread 自動終止（daemon=True）
       - 程式結束
```

---

## 錯誤處理與例外狀況

### 連線錯誤處理

1. **Modbus 連線中斷**
   - 偵測到連線中斷時，自動嘗試重新連線
   - 最多嘗試 5 次
   - 連續失敗 5 次後停止讀取

2. **讀取錯誤**
   - 讀取失敗時，錯誤計數器遞增
   - 連續錯誤 5 次後停止讀取
   - 輸出錯誤訊息到終端機

### 資料處理錯誤

1. **佇列滿載**
   - 自動移除最舊的資料
   - 確保最新資料優先處理

2. **CSV 寫入錯誤**
   - 捕獲例外並輸出錯誤訊息
   - 不影響資料收集繼續進行

### 前端錯誤處理

1. **API 請求失敗**
   - 顯示錯誤訊息
   - 不中斷圖表更新（會繼續嘗試）

2. **資料格式錯誤**
   - 檢查資料是否存在
   - 驗證資料長度

---

## 效能考量

### 記憶體使用

- **即時資料緩衝區**：最多 10000 個點（約 80 KB）
- **DAQ 資料佇列**：最多 1000 筆（約 1 MB）
- **前端圖表資料**：最多 5000 個點（約 40 KB）

### CPU 使用

- **資料讀取**：非阻塞式，避免 CPU 過載
- **資料處理**：短暫休息（10ms），避免忙等待
- **圖表更新**：200ms 間隔，平衡即時性和效能

### 磁碟 I/O

- **CSV 寫入**：每次寫入後立即 `flush()`，確保資料不遺失
- **檔案分檔**：避免單一檔案過大

---

## 擴展與自訂

### 修改通道數

目前系統固定為 3 通道，如需修改：

1. **prowavedaq.py**：修改資料處理邏輯
2. **csv_writer.py**：修改 `__init__` 和標題行
3. **main.py**：修改 `channels = 3` 為變數
4. **index.html**：修改 Chart.js 資料集數量

### 修改取樣率

在 `API/ProWaveDAQ.ini` 中修改 `sampleRate` 參數即可。

### 修改分檔間隔

在 `API/Master.ini` 中修改 `second` 參數即可。

### 新增功能

1. **新增 API 路由**：在 `main.py` 中新增 `@app.route()`
2. **新增前端頁面**：在 `templates/` 中新增 HTML
3. **新增資料處理**：在 `collection_loop()` 中新增邏輯

---

## 總結

本系統是一個完整的即時資料採集與可視化平台，主要特點：

1. **模組化設計**：各模組職責清晰，易於維護
2. **執行緒安全**：使用鎖定和佇列確保資料一致性
3. **記憶體管理**：限制緩衝區大小，避免記憶體過載
4. **錯誤處理**：完善的錯誤處理機制，提高穩定性
5. **Web 介面**：提供友善的使用者介面，無需終端機操作
6. **自動分檔**：根據時間間隔自動分檔儲存，便於資料管理

系統已針對高頻率資料採集進行優化，能夠穩定處理每秒 23,436 個資料點的資料流，並在瀏覽器中即時顯示。

---

**最後更新**：2025年12月17日
**文件版本**：4.1.0
**作者**：王建葦

### 版本更新記錄

#### Version 4.1.0 (2025-12-17)
- **重大更新**：SQL 上傳邏輯重構
  - 改為暫存檔案機制：資料先寫入暫存 CSV 檔案，定時上傳
  - 建立暫存檔案目錄（`.sql_temp`），檔案命名格式：`{timestamp}_sql_temp.csv`
  - 新增定時上傳執行緒（`sql_upload_timer_loop`），每 `sql_upload_interval` 秒檢查並上傳
  - 上傳成功後自動刪除暫存檔案，並立即建立新暫存檔案（避免資料溢出）
  - 停止時檢查並上傳所有剩餘暫存檔案
  - 降低記憶體使用：資料直接寫入檔案，不佔用記憶體緩衝區
  - 資料持久化：即使程式異常終止，暫存檔案仍保留
- **新增**：`sql_uploader.py` 新增 `upload_from_csv_file()` 方法
  - 從 CSV 檔案讀取資料並批次上傳至 SQL 伺服器
  - 支援自動建立資料表（如果不存在）
  - 包含錯誤處理與重試機制
- **更新**：技術文件更新
  - 更新 README.md 和 程式運作說明.md 以反映新的 SQL 上傳機制

#### Version 4.0.0 (2025-12-17)
- **改進**：程式碼註解完善
  - 為所有核心模組添加完整的中文註解
  - 所有函數和類別都有詳細的 docstring
  - 說明函數用途、參數、返回值、注意事項
  - 移除所有冗餘註解和步驟標記
  - 提升程式碼可讀性和可維護性
- **改進**：技術文件更新
  - 更新 README.md 和 程式運作說明.md 以符合目前程式碼
  - 確保文件與實際程式碼功能一致

#### Version 3.0.0 (2025-12)
- **重大更新**：重構資料讀取邏輯
  - 實現 Normal Mode 和 Bulk Mode 自動切換機制
  - 根據緩衝區狀態（buffer_count）動態選擇讀取模式
  - Normal Mode：當 buffer_count ≤ 123 時，從 Address 0x02 讀取
  - Bulk Mode：當 buffer_count > 123 時，從 Address 0x15 讀取（最多 9 個樣本）
  - FIFO buffer size(0x02) 連同資料一起讀出，確保資料一致性
- **改進**：讀取效率優化
  - 一次讀取 Header 和資料，減少 Modbus 通訊次數
  - 使用 `_read_registers_with_header()` 方法統一處理讀取邏輯
  - 參考 LabView 轉換版本（G.py）的實現方式
- **改進**：程式碼清理
  - 移除所有冗餘註解和步驟標記
  - 簡化程式碼結構，提升可讀性
- **改進**：即時資料顯示
  - 移除資料點數限制（原本限制 100000 個資料點）
  - 現在會保留並顯示所有資料

#### Version 1.0.2 (2025-11-06)
- **修復**：讀取中進入 config 頁面再回到主畫面時，狀態會自動恢復
- **新增**：`/status` API 端點，用於檢查資料收集狀態
- **新增**：檔案瀏覽功能（`/files_page`、`/files`、`/download`）
- **優化**：智慧緩衝區更新機制，無活躍連線時不更新即時資料緩衝區
- **新增**：前端狀態恢復功能（`checkAndRestoreStatus()`）
- **新增**：檔案瀏覽頁面（`files.html`），支援資料夾導航和檔案下載
# ProWaveDAQ Python 即時資料可視化系統 - 詳細程式運作說明

## 目錄

1. [專案概述](#專案概述)
2. [系統架構](#系統架構)
3. [核心模組詳細說明](#核心模組詳細說明)
4. [資料流程](#資料流程)
5. [Web 介面與 API](#web-介面與-api)
6. [執行緒架構](#執行緒架構)
7. [設定檔說明](#設定檔說明)
8. [檔案結構](#檔案結構)
9. [程式碼詳細解析](#程式碼詳細解析)
10. [運作流程](#運作流程)

---

## 專案概述

### 系統目的

ProWaveDAQ 即時資料可視化系統是一個基於 Python 的振動數據採集與可視化平台，主要功能包括：

1. **從 ProWaveDAQ 設備採集振動數據**：透過 Modbus RTU 協議從硬體設備讀取三通道振動數據
2. **即時資料可視化**：在瀏覽器中即時顯示連續振動曲線圖
3. **自動 CSV 儲存**：根據設定的時間間隔自動分檔儲存資料
4. **Web 介面控制**：提供完整的瀏覽器操作介面，無需終端機操作

### 技術棧

- **後端**：Python 3.9+
- **Web 框架**：Flask 3.1.2+
- **通訊協議**：Modbus RTU（透過 pymodbus 3.11.3+）
- **串列埠通訊**：pyserial 3.5+
- **前端可視化**：Chart.js 3.9.1
- **資料儲存**：CSV 格式

---

## 系統架構

### 整體架構圖

```
┌─────────────────────────────────────────────────────────────┐
│                      Web 瀏覽器（前端）                       │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  index.html: 即時圖表、控制按鈕、狀態顯示              │  │
│  │  config.html: 設定檔編輯介面                          │  │
│  └───────────────────────────────────────────────────────┘  │
└───────────────────────┬─────────────────────────────────────┘
                        │ HTTP/JSON
                        ▼
┌─────────────────────────────────────────────────────────────┐
│                 Flask Web 伺服器 (main.py)                   │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  Flask Thread: 處理 HTTP 請求                          │  │
│  │  - /: 主頁                                             │  │
│  │  - /data: 回傳即時資料                                 │  │
│  │  - /start: 啟動資料收集                                │  │
│  │  - /stop: 停止資料收集                                 │  │
│  │  - /config: 設定檔管理                                 │  │
│  └───────────────────────────────────────────────────────┘  │
└───────────────────────┬─────────────────────────────────────┘
                        │
        ┌───────────────┼───────────────┐
        │               │               │
        ▼               ▼               ▼
┌───────────────┐ ┌───────────────┐ ┌───────────────┐
│  Collection   │ │  Real-time    │ │  CSV Writer   │
│  Thread       │ │  Data Buffer  │ │  Thread       │
│  (資料收集迴圈)│ │  (記憶體變數) │ │  (檔案寫入)   │
└───────┬───────┘ └───────────────┘ └───────────────┘
        │
        ▼
┌─────────────────────────────────────────────────────────────┐
│              ProWaveDAQ 類別 (prowavedaq.py)                 │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  Reading Thread: Modbus RTU 讀取迴圈                  │  │
│  │  - 讀取設備資料                                        │  │
│  │  - 資料轉換（16位元 → 浮點數）                         │  │
│  │  - 放入資料佇列 (queue.Queue)                          │  │
│  └───────────────────────────────────────────────────────┘  │
└───────────────────────┬─────────────────────────────────────┘
                        │ Modbus RTU
                        ▼
┌─────────────────────────────────────────────────────────────┐
│              ProWaveDAQ 硬體設備                              │
│  - 串列埠：/dev/ttyUSB0                                      │
│  - 鮑率：3000000                                            │
│  - 取樣率：7812 Hz                                          │
│  - 從站 ID：1                                               │
└─────────────────────────────────────────────────────────────┘
```

### 模組關係

1. **main.py**（主控制程式）
   - 整合所有模組
   - 提供 Flask Web 服務
   - 管理執行緒和全域狀態

2. **prowavedaq.py**（硬體通訊模組）
   - 處理 Modbus RTU 通訊
   - 讀取設備資料
   - 資料轉換與佇列管理

3. **csv_writer.py**（資料儲存模組）
   - CSV 檔案建立與寫入
   - 自動分檔邏輯

4. **templates/**（前端介面）
   - HTML 模板與 JavaScript
   - Chart.js 圖表顯示

---

## 核心模組詳細說明

### 1. prowavedaq.py - ProWaveDAQ 類別

#### 類別結構

```python
class ProWaveDAQ:
    - client: ModbusSerialClient        # Modbus 連線物件
    - serial_port: str                  # 串列埠路徑
    - baud_rate: int                    # 鮑率
    - sample_rate: int                  # 取樣率 (Hz)
    - slave_id: int                     # Modbus 從站 ID
    - reading: bool                      # 讀取狀態旗標
    - reading_thread: Thread            # 讀取執行緒
    - data_queue: queue.Queue           # 資料佇列（最大 1000 筆）
    - counter: int                       # 讀取計數器
```

#### 主要方法

##### `init_devices(filename: str)`

**功能**：從 INI 設定檔初始化設備並建立 Modbus 連線

**運作流程**：
1. 讀取 `ProWaveDAQ.ini` 設定檔
   - `serialPort`: 串列埠路徑（預設 `/dev/ttyUSB0`）
   - `baudRate`: 鮑率（預設 `3000000`）
   - `sampleRate`: 取樣率（預設 `7812` Hz）
   - `slaveID`: 從站 ID（預設 `1`）

2. 建立 Modbus RTU 連線
   - 使用 `ModbusSerialClient` 建立串列埠連線
   - 設定參數：`parity='N'`, `stopbits=1`, `bytesize=8`, `framer="rtu"`
   - 連線超時設定為 1 秒

3. 讀取晶片 ID（驗證連線）
   - 讀取位址 `0x80` 的 3 個輸入暫存器
   - 顯示晶片 ID 用於驗證

4. 設定取樣率
   - 寫入位址 `0x01`，設定設備取樣率

**錯誤處理**：
- 連線失敗時輸出錯誤訊息並返回
- INI 檔案解析錯誤時使用預設值

##### `start_reading()`

**功能**：啟動背景執行緒開始讀取資料

**運作流程**：
1. 檢查是否已在讀取中（避免重複啟動）
2. 設定 `reading = True`
3. 建立並啟動背景執行緒執行 `_read_loop()`
4. 執行緒設定為 `daemon=True`（主程式結束時自動終止）

##### `_read_loop()`（Version 8.0.0 - 遵循手冊 Page 5 規範）

**功能**：主要的資料讀取迴圈（在獨立執行緒中執行）

**運作流程**（遵循原廠手冊 Page 5 規範）：

1. **讀取 FIFO 緩衝區大小**
   - 從位址 `0x02` 讀取 1 個輸入暫存器，取得 FIFO 緩衝區大小 `buffer_size`
   - 如果緩衝區為空（`buffer_size <= 0`），等待 2ms 後繼續

2. **計算讀取長度**
   - 限制單次讀取最大量：`read_count = min(buffer_size, MAX_READ_WORDS)`（123 個 Word）
   - 確保讀取完整的 X,Y,Z：`read_count = (read_count // CHANNELS) * CHANNELS`
   - 如果 `read_count == 0`，跳過此次讀取

3. **執行讀取（FC04，Start Address 0x02）**
   - 從 0x02 開始讀取 `read_count + 1` 個 Word（包含 Header）
   - 封包結構：`[Header(1 word), Data(N words)]`
   - 使用 `_read_data_packet()` 方法讀取完整封包

4. **解析封包**
   - `raw_packet[0]`：Header（讀取時的 FIFO 緩衝區大小，剩餘大小）
   - `raw_packet[1:]`：實際的振動資料（從 0x03 開始的資料）

5. **資料轉換**
   - 將 16 位元無符號整數轉換為有符號整數
   - 轉換公式：`signed = v if v < 32768 else v - 65536`
   - 除以 8192.0 進行正規化：`out.append(signed / 8192.0)`

6. **放入佇列**
   - 使用 `queue.put_nowait(data)` 放入佇列
   - 如果佇列已滿（5000 筆），移除最舊的資料（FIFO）

7. **錯誤處理**
   - 讀取失敗時輸出錯誤訊息並繼續
   - 連線錯誤時會導致讀取失敗，但不會自動重連（需重新初始化）

**設計理由**：
- 遵循原廠手冊 Page 5 規範，確保通訊正確性
- 一次讀取完整封包，減少讀取次數，提升效能
- 確保讀取完整的 X,Y,Z（3的倍數），避免通道錯位
- 使用佇列緩衝，避免資料遺失

**資料格式**：
- 輸入：16 位元無符號整數陣列（從 Modbus 暫存器讀取）
- 輸出：浮點數陣列（已正規化，範圍約 -4.0 到 4.0）

##### `get_data() -> List[float]`

**功能**：非阻塞式取得資料（從佇列取出）

**運作方式**：
- 使用 `queue.get_nowait()` 非阻塞取得資料
- 如果佇列為空，返回空陣列 `[]`
- 避免阻塞主執行緒

##### `stop_reading()`

**功能**：停止讀取並清理資源

**運作流程**：
1. 設定 `reading = False`（停止讀取迴圈）
2. 等待讀取執行緒結束（`join()`）
3. 清空資料佇列
4. 關閉 Modbus 連線

##### `_reconnect() -> bool`

**功能**：重新建立 Modbus 連線

**運作流程**：
1. 關閉舊連線
2. 重新建立 `ModbusSerialClient`
3. 嘗試連線
4. 設定從站 ID
5. 返回連線成功/失敗狀態

---

### 2. csv_writer.py - CSVWriter 類別

#### 類別結構

```python
class CSVWriter:
    - channels: int                    # 通道數量（固定為 3）
    - output_dir: str                   # 輸出目錄路徑
    - label: str                        # 資料標籤
    - file_counter: int                 # 檔案計數器
    - current_file: file                # 當前開啟的檔案物件
    - writer: csv.writer                # CSV 寫入器物件
```

#### 主要方法

##### `__init__(channels, output_dir, label)`

**功能**：初始化 CSV 寫入器

**運作流程**：
1. 儲存參數（通道數、輸出目錄、標籤）
2. 初始化檔案計數器為 1
3. 建立輸出目錄（如果不存在）
4. 建立第一個 CSV 檔案

##### `_create_new_file()`

**功能**：建立新的 CSV 檔案

**運作流程**：
1. 產生檔案名稱：`{timestamp}_{label}_{file_counter:03d}.csv`
   - 時間戳記格式：`YYYYMMDDHHMMSS`
   - 檔案計數器：3 位數，從 001 開始
2. 開啟檔案（UTF-8 編碼）
3. 建立 CSV 寫入器
4. 寫入標題行：`['Timestamp', 'Channel_1', 'Channel_2', 'Channel_3']`
5. 立即寫入磁碟（`flush()`）

**檔案命名範例**：
- `20250106120000_test_001.csv`
- `20250106120000_test_002.csv`

##### `add_data_block(data: List[float])`

**功能**：將資料區塊寫入 CSV 檔案

**運作流程**：
1. 檢查資料是否為空
2. 取得當前時間戳記（ISO 格式）
3. **按通道分組寫入**：
   - 資料格式：`[ch1_val, ch2_val, ch3_val, ch1_val, ch2_val, ch3_val, ...]`
   - 每 3 個資料點為一組（對應 3 個通道）
   - 寫入格式：`[timestamp, channel_1_value, channel_2_value, channel_3_value]`
4. 如果資料不足 3 的倍數，不足的通道填充 0.0
5. 立即寫入磁碟（`flush()`）

**資料寫入範例**：
```csv
Timestamp,Channel_1,Channel_2,Channel_3
2025-01-06T12:00:00.123456,0.123,0.456,0.789
2025-01-06T12:00:00.123489,0.234,0.567,0.890
```

##### `update_filename()`

**功能**：建立新檔案（分檔）

**運作流程**：
1. 關閉當前檔案
2. 檔案計數器遞增
3. 呼叫 `_create_new_file()` 建立新檔案

##### `close()`

**功能**：關閉 CSV 檔案

**運作流程**：
1. 關閉檔案物件
2. 清空檔案和寫入器參考

---

### 3. main.py - Flask Web 伺服器與主控制程式

#### 全域狀態變數（Version 7.0.0）

```python
app: Flask                              # Flask 應用程式實例
web_data_queue: queue.Queue             # Web 顯示專用佇列（降頻後的資料）
WEB_DOWNSAMPLE_RATIO: int = 50          # 降頻比例（每 50 點取 1 點）
csv_data_queue: queue.Queue             # CSV 資料佇列（原始資料）
sql_data_queue: queue.Queue             # SQL 資料佇列（原始資料）
data_lock: threading.Lock              # 資料存取鎖定
is_collecting: bool                     # 資料收集狀態旗標
collection_thread: Thread               # 資料收集執行緒
daq_instance: ProWaveDAQ                # DAQ 實例
csv_writer_instance: CSVWriter         # CSV 寫入器實例
data_counter: int                       # 資料點計數器
target_size: int                        # 每個 CSV 檔案的目標資料點數
current_data_size: int                  # 當前檔案已寫入的資料點數
```

#### 核心函數

##### `update_realtime_data(data: List[float])`（Version 7.0.0）

**功能**：更新即時資料（針對 Web 顯示進行降頻處理）

**核心架構**：
- 降頻佇列：`web_data_queue`（最大 10,000 筆）
- 降頻比例：50（每 50 點取 1 點）
- 原始採樣率：7812 Hz → 降頻後約 156 Hz
- 前端資料傳輸量減少約 98%

**運作流程**：

1. **防止佇列溢位**
   - 如果 `web_data_queue` 已滿，丟棄 10 筆舊資料
   - 保護記憶體，避免前端卡死時導致記憶體溢出

2. **降頻處理（Downsampling）**
   - 資料格式：`[X1, Y1, Z1, X2, Y2, Z2, ...]`（交錯格式）
   - 計算步長：`step = channels * WEB_DOWNSAMPLE_RATIO = 3 * 50 = 150`
   - 使用步進切片：`for i in range(0, len(data), step)`
   - 確保每次取出的都是完整的 `[X, Y, Z]` 一組
   - 擷取資料片段並放入降頻後的陣列

3. **放入 Web 佇列**
   - 如果降頻後的資料不為空，放入 `web_data_queue`
   - 使用 `data_lock` 確保執行緒安全

4. **更新計數器**
   - 更新 `data_counter`（總資料點數，用於狀態顯示）

**設計理由**：
- 降頻處理：大幅減少前端資料傳輸量和繪圖負擔
- 佇列機制：使用佇列而非大型緩衝區，記憶體使用更穩定
- 原始資料保留：CSV 和 SQL 仍使用原始資料（不降頻），確保資料完整性
- 自動清理：佇列滿時自動丟棄舊資料，避免記憶體溢出

##### `get_data() -> Dict`

**功能**：前端輪詢 API，返回降頻後的增量資料

**返回格式**：
```python
{
    "success": True,
    "data": [0.123, 0.456, 0.789, ...],  # 降頻後的增量資料（自上次請求後的新資料）
    "counter": 234360,  # 總資料點數（原始資料）
    "sample_rate": 7812,  # 取樣率
    "is_collecting": True,  # 收集狀態
    "start_time": "2025-12-22T12:00:00"  # 起始時間（如果已開始）
}
```

**返回格式**：
```python
{
    "data": [0.123, 0.456, 0.789, ...],  # 完整的資料陣列（234,360 個資料點）
    "time": [0, 0, 0, 0, 0, 0, 0, 0, 0, 9.5],  # 時間陣列（前9個為0，最後一個有時間值）
    "count": 234360  # 已寫入的資料點數
}
```

**運作流程**：
1. 取得資料鎖定（`data_lock`）
2. 從 `web_data_queue` 取出所有累積的資料（非阻塞）
3. 將所有資料合併成一個陣列
4. 返回 JSON 回應，包含：
   - `data`：降頻後的增量資料（前端直接 push 進圖表）
   - `counter`：總資料點數（用於狀態顯示）
   - `is_collecting`：收集狀態（前端依據此旗標判斷是否停止）
   - `start_time`：起始時間（如果已開始收集）

**設計理由**：
- 增量更新：只返回新資料，減少網路傳輸量
- 降頻資料：前端接收的是降頻後的資料，大幅減少繪圖負擔
- 狀態同步：返回 `is_collecting` 狀態，前端可以自動同步
- 執行緒安全：使用鎖定確保資料一致性

#### Flask 路由

##### `@app.route('/')` - 主頁

**功能**：顯示主頁面（包含設定表單、Label 輸入、開始/停止按鈕、即時圖表）

**回應**：渲染 `templates/index.html` 模板

##### `@app.route('/data')` - 取得即時資料

**功能**：回傳目前最新資料給前端（JSON 格式），並追蹤活躍連線狀態

**回應格式**：
```json
{
  "success": true,
  "data": [0.123, 0.456, 0.789, ...],
  "counter": 12345
}
```

**運作流程**：
1. **更新請求時間**
   - 更新 `last_data_request_time` 為當前時間
   - 表示有活躍的前端連線（用於智慧緩衝區更新）
   
2. 取得即時資料副本
3. 取得資料點計數器
4. 返回 JSON 回應

**設計理由**：
- 追蹤前端連線狀態，優化資源使用
- 無連線時不更新緩衝區，節省 CPU 和記憶體

##### `@app.route('/status')` - 檢查資料收集狀態

**功能**：檢查資料收集狀態（用於前端狀態恢復）

**回應格式**：
```json
{
  "success": true,
  "is_collecting": true,
  "counter": 12345
}
```

**運作流程**：
1. 取得 `is_collecting` 狀態
2. 取得資料點計數器
3. 返回 JSON 回應

**使用場景**：
- 前端頁面載入時檢查後端狀態
- 如果後端正在收集資料，前端自動恢復狀態並開始更新圖表

##### `@app.route('/config', methods=['GET', 'POST'])` - 設定檔管理

**GET 請求**：
- 讀取 `API/ProWaveDAQ.ini`、`API/csv.ini` 和 `API/sql.ini`
- 渲染 `templates/config.html`，顯示設定檔內容供編輯

**POST 請求**：
- 接收表單資料（三個設定檔的內容）
- 寫入 `API/ProWaveDAQ.ini`、`API/csv.ini` 和 `API/sql.ini`
- 返回成功/失敗 JSON 回應

**錯誤處理**：
- 檔案讀取失敗時使用預設內容
- 寫入失敗時返回錯誤訊息

##### `@app.route('/files_page')` - 檔案瀏覽頁面

**功能**：顯示檔案瀏覽頁面

**回應**：渲染 `templates/files.html` 模板

##### `@app.route('/files')` - 列出檔案和資料夾

**功能**：列出 `output/ProWaveDAQ/` 目錄中的檔案和資料夾

**查詢參數**：
- `path` (可選)：要瀏覽的子目錄路徑

**回應格式**：
```json
{
  "success": true,
  "items": [
    {
      "name": "20240101120000_test_001",
      "type": "directory",
      "path": "20240101120000_test_001"
    },
    {
      "name": "data.csv",
      "type": "file",
      "path": "data.csv",
      "size": 1024
    }
  ],
  "current_path": ""
}
```

**運作流程**：
1. 取得路徑參數（如果提供）
2. 安全檢查：確保路徑在 `output/ProWaveDAQ/` 目錄內
3. 列出目錄內容
4. 區分資料夾和檔案
5. 返回 JSON 回應

**安全機制**：
- 路徑標準化檢查，防止目錄遍歷攻擊
- 只允許存取 `output/ProWaveDAQ/` 目錄下的檔案

##### `@app.route('/download')` - 下載檔案

**功能**：下載指定的 CSV 檔案

**查詢參數**：
- `path` (必需)：要下載的檔案路徑

**運作流程**：
1. 取得路徑參數
2. 安全檢查：確保路徑在 `output/ProWaveDAQ/` 目錄內
3. 驗證檔案存在且為檔案（非資料夾）
4. 使用 `send_from_directory()` 發送檔案

**安全機制**：
- 路徑標準化檢查，防止目錄遍歷攻擊
- 只允許下載 `output/ProWaveDAQ/` 目錄下的檔案

##### `@app.route('/start', methods=['POST'])` - 啟動資料收集

**功能**：啟動資料收集、CSV 寫入和即時顯示

**請求格式**：
```json
{
  "label": "test_001"
}
```

**運作流程**：

1. **檢查狀態**
   - 如果已在收集，返回錯誤

2. **驗證 Label**
   - 如果 Label 為空，返回錯誤

3. **重置狀態**
   - 清空即時資料緩衝區
   - 重置資料點計數器
   - 重置當前資料大小
   - 重置請求時間追蹤（`last_data_request_time = 0`）

4. **載入設定檔**
   - 讀取 `API/csv.ini`，取得 `DumpUnit.second`（CSV 分檔時間間隔，預設 5 秒）
   - 讀取 `API/sql.ini`，取得 `DumpUnit.second`（SQL 上傳間隔，預設 5 秒）

5. **初始化 DAQ**
   - 建立 `ProWaveDAQ` 實例
   - 從 `API/ProWaveDAQ.ini` 初始化設備
   - 取得取樣率（預設 7812 Hz）
   - 通道數固定為 3

6. **計算目標大小**
   - `target_size = second × sample_rate × channels`
   - 範例：5 秒 × 7812 Hz × 3 通道 = 117,180 個資料點

7. **建立輸出目錄**
   - 路徑：`output/ProWaveDAQ/{timestamp}_{label}/`
   - 時間戳記格式：`YYYYMMDDHHMMSS`

8. **初始化 CSV Writer**
   - 建立 `CSVWriter` 實例

9. **啟動資料收集執行緒**
   - 設定 `is_collecting = True`
   - 建立並啟動 `collection_loop` 執行緒（daemon=True）

10. **啟動 DAQ 讀取**
    - 呼叫 `daq_instance.start_reading()`

11. **返回成功回應**
    - 包含取樣率和分檔間隔資訊

**回應格式**：
```json
{
  "success": true,
  "message": "資料收集已啟動 (取樣率: 7812 Hz, 分檔間隔: 5 秒)"
}
```

##### `@app.route('/stop', methods=['POST'])` - 停止資料收集

**功能**：停止所有執行緒並安全關閉

**運作流程**：
1. 檢查是否在收集中（如果未在收集，返回錯誤）
2. 設定 `is_collecting = False`（停止收集迴圈）
3. 停止 DAQ 讀取（`daq_instance.stop_reading()`）
4. 關閉 CSV Writer（`csv_writer_instance.close()`）
5. 返回成功回應

##### `collection_loop()` - 資料收集主迴圈

**功能**：在獨立執行緒中執行，持續處理資料並分發到即時顯示和 CSV 儲存

**運作流程**：

1. **主迴圈**（`while is_collecting`）：
   
   a. **從 DAQ 取得資料**
      - 呼叫 `daq_instance.get_data()`（非阻塞）
      - 如果沒有資料，返回空陣列
   
   b. **持續處理佇列中的所有資料**
      - `while data and len(data) > 0`：
      
      i. **更新即時顯示**
         - 呼叫 `update_realtime_data(data)`
         - 資料會出現在前端圖表
      
      ii. **寫入 CSV（分檔邏輯）**
          
          - **累積資料大小**：`current_data_size += len(data)`
          
          - **如果 `current_data_size < target_size`**：
            - 資料還未達到分檔門檻，直接寫入當前檔案
            - `csv_writer_instance.add_data_block(data)`
          
          - **如果 `current_data_size >= target_size`**：
            - 需要分檔處理
            - 計算剩餘空間：`empty_space = target_size - (current_data_size - len(data))`
            - **分批處理**（`while current_data_size >= target_size`）：
              - 取出一個完整批次：`batch = data[:empty_space]`
              - 寫入當前檔案
              - 更新檔案名稱（建立新檔案）：`csv_writer_instance.update_filename()`
              - 減少累積大小：`current_data_size -= target_size`
            - **處理剩餘資料**：
              - 如果還有剩餘資料（`pending = len(data) - empty_space`）：
                - 寫入新檔案：`csv_writer_instance.add_data_block(remaining_data)`
                - 更新累積大小：`current_data_size = pending`
              - 否則：`current_data_size = 0`
      
      iii. **繼續從佇列取得下一筆資料**
          - `data = daq_instance.get_data()`
   
   c. **短暫休息**
      - `time.sleep(0.01)`（10ms），避免 CPU 過載

2. **錯誤處理**：
   - 捕獲所有例外並輸出錯誤訊息
   - 發生錯誤時等待 0.1 秒後繼續

**分檔邏輯範例**：

假設 `target_size = 117180`（5 秒 × 7812 Hz × 3 通道）

- **情況 1**：`current_data_size = 100000`，新資料 `len(data) = 10000`
  - 總計：110000 < 117180
  - 直接寫入，`current_data_size = 110000`

- **情況 2**：`current_data_size = 110000`，新資料 `len(data) = 20000`
  - 總計：130000 ≥ 117180
  - 第一個批次：`empty_space = 117180 - 110000 = 7180`
  - 寫入 7180 個資料點，更新檔案，`current_data_size = 0`
  - 剩餘：`20000 - 7180 = 12820`
  - 寫入剩餘資料到新檔案，`current_data_size = 12820`

##### `run_flask_server()` - Flask 伺服器執行函數

**功能**：在獨立執行緒中執行 Flask 伺服器

**設定**：
- 主機：`0.0.0.0`（監聽所有網路介面）
- 埠：`8080`
- 除錯模式：`False`
- 重新載入器：`False`（避免與執行緒衝突）

##### `main()` - 主函數

**功能**：程式入口點

**運作流程**：
1. 輸出啟動訊息
2. 在背景執行緒中啟動 Flask 伺服器（daemon=True）
3. 主執行緒進入無限迴圈（`while True: time.sleep(1)`）
4. 等待使用者按 Ctrl+C 中斷
5. **清理資源**：
   - 如果正在收集，停止收集
   - 停止 DAQ
   - 關閉 CSV Writer
6. 輸出關閉訊息

---

## 資料流程

### 完整資料流程圖

```
ProWaveDAQ 設備
    │
    │ Modbus RTU 通訊
    │ (串列埠: /dev/ttyUSB0, 鮑率: 3000000)
    ▼
prowavedaq.py::ProWaveDAQ
    │
    │ _read_loop() 執行緒
    │ - 讀取位址 0x02 的資料長度
    │ - 根據長度讀取資料暫存器
    │ - 16 位元整數 → 浮點數轉換（÷8192.0）
    │
    ▼
queue.Queue (最大 1000 筆)
    │
    │ get_data() 非阻塞取得
    ▼
main.py::collection_loop() 執行緒
    │
    ├─→ update_realtime_data()
    │   │
    │   ▼
    │   realtime_data (List[float], 最多 10000 點)
    │   │
    │   ▼
    │   Flask /data API
    │   │
    │   ▼
    │   前端 Chart.js (每 200ms 更新)
    │
    ├─→ csv_writer.add_data_block()
    │       │
    │       ▼
    │   分檔邏輯判斷
    │       │
    │       ├─→ current_data_size < target_size
    │       │   └─→ 直接寫入當前檔案
    │       │
    │       └─→ current_data_size >= target_size
    │           ├─→ 寫入完整批次
    │           ├─→ update_filename() (建立新檔案)
    │           └─→ 處理剩餘資料
    │               │
    │               ▼
    │           CSV 檔案
    │           output/ProWaveDAQ/{timestamp}_{label}/{timestamp}_{label}_{001-999}.csv
    │
    └─→ SQL Uploader（如果啟用）
            │
            ▼
        寫入暫存 CSV 檔案
            │
            ▼
        .sql_temp/{timestamp}_sql_temp.csv
            │
            ▼
        定時上傳執行緒（每 sql_upload_interval 秒）
            │
            ├─→ 讀取暫存檔案
            ├─→ 批次上傳 (executemany)
            ├─→ 重試機制 (最多 3 次)
            ├─→ 失敗保留 (暫存檔案不刪除)
            ├─→ 成功後刪除暫存檔案
            └─→ 建立新暫存檔案
                │
                ▼
            MariaDB/MySQL 資料庫
            vibration_data 資料表（動態建立，表名與 CSV 檔名對應）
```

### 資料格式轉換

1. **硬體 → ProWaveDAQ**
   - 輸入：16 位元有符號整數（0-65535）
   - 轉換：`value = (value < 32768) ? value : value - 65536`
   - 正規化：`float_value = value / 8192.0`
   - 輸出：浮點數陣列

2. **ProWaveDAQ → 即時顯示**
   - 格式：`[ch1, ch2, ch3, ch1, ch2, ch3, ...]`
   - 前端按每 3 個一組分離通道

3. **ProWaveDAQ → CSV**
   - 格式：`[ch1, ch2, ch3, ch1, ch2, ch3, ...]`
   - CSV 寫入器按每 3 個一組寫入一行
   - CSV 格式：`Timestamp,Channel_1,Channel_2,Channel_3`

### 資料量計算

**每秒資料量**：
- 取樣率：7812 Hz
- 通道數：3
- **每秒資料點數**：7812 × 3 = 23,436 個資料點

**每個 CSV 檔案資料量**（預設 5 秒）：
- **資料點數**：7812 × 3 × 5 = 117,180 個資料點
- **檔案大小**（估算）：約 3-5 MB（取決於時間戳記長度）

**記憶體使用**：
- 即時資料緩衝區：固定 234,360 個資料點（約 1.87 MB，使用 NumPy Array）
- 時間緩衝區：固定 10 個時間點（約 80 bytes）
- DAQ 資料佇列：最多 5000 筆（每筆約 123 個點，約 5 MB）
- CSV 資料佇列：最多 1000 筆（每筆約 123 個點，約 1 MB）
- SQL 資料佇列：最多 1000 筆（每筆約 123 個點，約 1 MB）

---

## Web 介面與 API

### 前端頁面

#### index.html - 主頁面

**功能**：
- 顯示即時資料曲線圖
- 提供 Label 輸入欄位
- 開始/停止按鈕
- 狀態顯示（資料點數、收集狀態）

**JavaScript 功能**：

1. **Chart.js 初始化**
   - 建立 3 個資料集（通道 1、2、3）
   - 設定為折線圖，無動畫（`duration: 0`）
   - Y 軸不從零開始（`beginAtZero: false`）
   - 不顯示 X 軸標籤

2. **updateChart()** - 更新圖表（Version 7.0.0 增量更新）
   - 每 100ms 呼叫一次（`setInterval(updateChart, 100)`）
   - 從 `/data` API 取得降頻後的增量資料
   - 檢查後端 `is_collecting` 狀態，自動同步前端 UI
   - 將資料按通道分組（每 3 個一組）
   - 使用 `push()` 將新資料加到圖表右側
   - 使用 `splice()` 移除左側舊資料，維持固定視窗大小（500 點）
   - 關閉動畫：`animation: false`（減少閃爍並提升即時性）
   - 關閉互動提示：`interaction.mode: 'none'`（減少 CPU 消耗）
   - 不顯示資料點：`pointRadius: 0`（提升繪圖效能）

3. **startCollection()** - 開始收集
   - 驗證 Label 是否輸入
   - 發送 POST 請求到 `/start`
   - 啟動圖表更新定時器
   - 更新 UI 狀態（禁用開始按鈕，啟用停止按鈕）

4. **stopCollection()** - 停止收集
   - 發送 POST 請求到 `/stop`
   - 停止圖表更新定時器
   - 更新 UI 狀態

#### config.html - 設定檔編輯頁面

**功能**：
- 顯示兩個設定檔的內容（文字區域）
- 提供儲存按鈕

**JavaScript 功能**：
- `saveConfig()` - 發送 POST 請求儲存設定檔

#### files.html - 檔案瀏覽頁面

**功能**：
- 顯示 `output/ProWaveDAQ/` 目錄中的檔案和資料夾列表
- 支援資料夾導航
- 支援檔案下載

**JavaScript 功能**：

1. **loadFiles(path)** - 載入檔案列表
   - 呼叫 `/files` API 取得目錄內容
   - 顯示檔案和資料夾列表

2. **displayFiles(items, path)** - 顯示檔案列表
   - 區分資料夾（📁）和檔案（📄）
   - 顯示檔案大小（自動格式化）
   - 為資料夾提供「進入」按鈕
   - 為檔案提供「下載」按鈕

3. **updateBreadcrumb(path)** - 更新麵包屑導航
   - 顯示當前路徑
   - 支援點擊返回上層目錄

4. **navigateTo(path)** - 導航到指定路徑
   - 載入指定目錄的內容

5. **downloadFile(path)** - 下載檔案
   - 開啟 `/download` API 下載檔案

**檔案大小格式化**：
- 自動將位元組轉換為 B、KB、MB、GB

#### index.html - 主頁面（更新）

**新增功能**：

1. **checkAndRestoreStatus()** - 檢查並恢復狀態
   - 頁面載入時呼叫 `/status` API
   - 如果後端正在收集資料，自動恢復前端狀態：
     - 啟用停止按鈕
     - 禁用開始按鈕和 Label 輸入
     - 開始更新圖表
     - 更新狀態顯示

**設計理由**：
- 解決「讀取中進入 config 頁面再回到主畫面會卡狀態」的問題
- 確保前端狀態與後端狀態同步

### API 端點

| 路由 | 方法 | 功能 | 請求格式 | 回應格式 |
|------|------|------|----------|----------|
| `/` | GET | 主頁 | - | HTML |
| `/data` | GET | 取得即時資料 | - | JSON |
| `/status` | GET | 檢查資料收集狀態 | - | JSON |
| `/config` | GET | 顯示設定檔編輯頁 | - | HTML |
| `/config` | POST | 儲存設定檔 | FormData | JSON |
| `/start` | POST | 啟動資料收集 | JSON | JSON |
| `/stop` | POST | 停止資料收集 | - | JSON |
| `/files_page` | GET | 檔案瀏覽頁面 | - | HTML |
| `/files` | GET | 列出檔案和資料夾 | `?path=<路徑>` | JSON |
| `/download` | GET | 下載檔案 | `?path=<路徑>` | 檔案下載 |

---

## 執行緒架構

### 執行緒列表

| 執行緒 | 功能 | 類型 | 狀態管理 |
|--------|------|------|----------|
| **主執行緒** | 控制流程、等待中斷 | 主執行緒 | - |
| **Flask Thread** | 處理 HTTP 請求 | daemon=True | 主程式結束時自動終止 |
| **DAQ Reading Thread** (ProWaveDAQ) | Modbus 資料讀取迴圈 | daemon=True | `reading` 旗標 |
| **Collection Thread** (main.py) | 資料收集與分發迴圈 | daemon=True | `is_collecting` 旗標 |
| **CSV Writer Thread** (main.py) | CSV 檔案寫入迴圈 | daemon=True | `is_collecting` 旗標 + 佇列狀態 |
| **SQL Writer Thread** (main.py) | SQL 暫存檔案寫入迴圈 | daemon=True | `is_collecting` 旗標 + 佇列狀態 |

### 執行緒同步

1. **資料鎖定** (`data_lock`)
   - 保護 `realtime_data` 和 `data_counter`
   - 使用 `threading.Lock()` 確保執行緒安全

2. **佇列同步** (`data_queue`, `csv_data_queue`, `sql_data_queue`)
   - 使用 `queue.Queue`（執行緒安全）
   - DAQ 資料佇列：最大容量 5000 筆
   - CSV 資料佇列：最大容量 1000 筆
   - SQL 資料佇列：最大容量 1000 筆
   - 避免記憶體過載

3. **請求時間追蹤鎖定** (`data_request_lock`)
   - 保護 `last_data_request_time` 變數
   - 用於追蹤活躍的前端連線

4. **狀態旗標**
   - `is_collecting`: 控制收集迴圈
   - `reading`: 控制讀取迴圈

### 執行緒生命週期

```
啟動階段：
1. main() 啟動
2. Flask Thread 啟動（背景）
3. 主執行緒進入等待迴圈

資料收集階段（/start）：
1. 初始化 DAQ、CSV Writer 和 SQL Uploader
2. Collection Thread 啟動
3. CSV Writer Thread 啟動（如果啟用 CSV）
4. SQL Writer Thread 啟動（如果啟用 SQL）
5. DAQ Reading Thread 啟動
6. 多個執行緒並行運作

停止階段（/stop 或 Ctrl+C）：
1. 設定 is_collecting = False
2. Collection Thread 結束
3. 等待 CSV 和 SQL 佇列處理完成
4. CSV Writer Thread 結束
5. SQL Writer Thread 結束
6. 設定 reading = False
7. DAQ Reading Thread 結束
8. 關閉 CSV Writer 和 SQL Uploader
9. 關閉 Modbus 連線
```

---

## 設定檔說明

### API/ProWaveDAQ.ini

**格式**：INI 檔案

**區段**：`[ProWaveDAQ]`

**參數**：

| 參數 | 說明 | 預設值 | 範例 |
|------|------|--------|------|
| `serialPort` | 串列埠路徑 | `/dev/ttyUSB0` | `/dev/ttyUSB0` |
| `baudRate` | 鮑率（bps） | `3000000` | `3000000` |
| `sampleRate` | 取樣率（Hz） | `7812` | `7812` |
| `slaveID` | Modbus 從站 ID | `1` | `1` |

**範例**：
```ini
[ProWaveDAQ]
serialPort = /dev/ttyUSB0
baudRate = 3000000
sampleRate = 7812
slaveID = 1
```

**注意事項**：
- 串列埠路徑需根據實際設備調整
- 鮑率和取樣率需與硬體設備匹配
- 從站 ID 需與設備設定一致

### API/csv.ini

**格式**：INI 檔案

**區段**：`[DumpUnit]`

**參數**：

| 參數 | 說明 | 預設值 | 範例 |
|------|------|--------|------|
| `second` | 每個 CSV 檔案的資料時間長度（秒） | `60` | `1800` |

**範例**：
```ini
[CSVServer]
enabled = false

[DumpUnit]
second = 1800
```

**分檔邏輯**：
- 每個 CSV 檔案包含的資料點數 = `second × sampleRate × channels`
- 例如：1800 秒 × 7812 Hz × 3 通道 = 42,184,800 個資料點
- 系統會自動計算並在達到目標大小時建立新檔案

### API/sql.ini

**格式**：INI 檔案

**區段**：`[SQLServer]` 和 `[DumpUnit]`

**參數**：

| 區段 | 參數 | 說明 | 預設值 | 範例 |
|------|------|------|--------|------|
| `[SQLServer]` | `enabled` | 是否啟用 SQL 上傳 | `false` | `true` |
| `[SQLServer]` | `host` | SQL 伺服器位置 | `localhost` | `192.168.9.13` |
| `[SQLServer]` | `port` | 連接埠 | `3306` | `3306` |
| `[SQLServer]` | `user` | 使用者名稱 | `root` | `raspberrypi` |
| `[SQLServer]` | `password` | 密碼 | `""` | `Raspberry@Pi` |
| `[SQLServer]` | `database` | 資料庫名稱 | `prowavedaq` | `daq-data` |
| `[DumpUnit]` | `second` | SQL 上傳間隔（秒） | `5` | `600` |

**範例**：
```ini
[SQLServer]
enabled = false
host = 192.168.9.13
port = 3306
user = raspberrypi
password = Raspberry@Pi
database = daq-data

[DumpUnit]
second = 600
```

**SQL 上傳邏輯**：
- SQL 上傳採用暫存檔案機制，資料先寫入暫存 CSV 檔案
- 每 `second` 秒定時檢查並上傳暫存檔案
- 例如：600 秒 → 每 600 秒上傳一次暫存檔案

---

## 檔案結構

### 專案目錄結構

```
ProWaveDAQ_Python_Visualization_Unit/
│
├── API/                              # 設定檔目錄
│   ├── ProWaveDAQ.ini                # ProWaveDAQ 設備設定檔
│   ├── csv.ini                       # CSV 分檔間隔設定檔
│   └── sql.ini                       # SQL 伺服器連線設定檔和上傳間隔設定檔
│
├── templates/                         # HTML 模板目錄
│   ├── index.html                    # 主頁面（即時圖表、控制按鈕）
│   ├── config.html                   # 設定檔編輯頁面
│   └── files.html                    # 檔案瀏覽頁面
│
├── output/                            # 輸出目錄（自動建立）
│   └── ProWaveDAQ/                   # CSV 檔案輸出目錄
│       └── {timestamp}_{label}/      # 每次收集的資料夾
│           ├── {timestamp}_{label}_001.csv
│           ├── {timestamp}_{label}_002.csv
│           ├── ...
│           └── .sql_temp/            # SQL 暫存檔案目錄（如果啟用 SQL）
│               └── {timestamp}_sql_temp.csv
│
├── prowavedaq.py                     # ProWaveDAQ 核心模組（Modbus 通訊）
├── csv_writer.py                     # CSV 寫入器模組
├── main.py                           # 主控制程式（Flask Web 伺服器）
├── requirements.txt                  # Python 依賴套件列表
├── deploy.sh                         # 自動部署腳本
├── run.sh                            # 啟動腳本
├── README.md                         # 使用說明文件
└── 程式運作說明.md                   # 本文件（詳細程式運作說明）
```

### 檔案說明

| 檔案 | 說明 | 行數 | 主要功能 |
|------|------|------|----------|
| `main.py` | 主控制程式 | 434 | Flask Web 伺服器、執行緒管理、資料收集迴圈、檔案瀏覽 API |
| `prowavedaq.py` | 硬體通訊模組 | 408 | Modbus RTU 通訊、資料讀取、資料轉換 |
| `csv_writer.py` | CSV 寫入器 | 110 | CSV 檔案建立、資料寫入、分檔邏輯 |
| `templates/index.html` | 主頁面 | 405 | 即時圖表、控制介面、JavaScript 邏輯、狀態恢復 |
| `templates/config.html` | 設定檔編輯頁 | 140 | 設定檔編輯介面 |
| `templates/files.html` | 檔案瀏覽頁 | 285 | 檔案列表、資料夾導航、檔案下載 |
| `requirements.txt` | 依賴套件 | 32 | Python 套件版本列表 |
| `deploy.sh` | 部署腳本 | 191 | 自動安裝依賴、設定權限 |
| `run.sh` | 啟動腳本 | 5 | 啟動虛擬環境並執行主程式 |

---

## 程式碼詳細解析

### 關鍵程式碼片段

#### 1. 資料讀取邏輯（prowavedaq.py）

```python
# 讀取模式判斷
if self.buffer_count <= self.BULK_TRIGGER_SIZE:
    # Normal Mode: 從 Address 0x02 讀取
    collected_data, remaining = self._read_normal_data(samples_to_read)
else:
    # Bulk Mode: 從 Address 0x15 讀取（最多 9 個樣本）
    collected_data, remaining = self._read_bulk_data(samples_to_read)

# 讀取方法（包含 Header）
def _read_registers_with_header(self, address, count, mode_name):
    read_count = count + 1  # Header + 資料
    result = self.client.read_input_registers(address=address, count=read_count)
    raw_data = result.registers
    payload_data = raw_data[1:]  # 實際資料（不含 Header）
    remaining_samples = raw_data[0]  # 剩餘樣本數（從 Header 取得）
    return payload_data, remaining_samples
```

**設計理由**：
- 根據緩衝區狀態自動切換 Normal Mode 和 Bulk Mode，優化讀取效率
- FIFO buffer size(0x02) 連同資料一起讀出，確保資料一致性
- Normal Mode：適合資料量較小的情況（≤ 123 個樣本）
- Bulk Mode：適合資料量較大的情況（> 123 個樣本），使用專用的 Bulk 地址

#### 2. 資料轉換邏輯（prowavedaq.py）

```python
# 16 位元有符號整數轉換
value = vib_data[i] if vib_data[i] < 32768 else vib_data[i] - 65536
processed_data.append(value / 8192.0)
```

**轉換說明**：
- 16 位元無符號整數範圍：0-65535
- 有符號整數範圍：-32768 到 32767
- 轉換規則：≥32768 的視為負數（減去 65536）
- 正規化：除以 8192.0（設備特定的轉換係數）

#### 3. 分檔邏輯（main.py）

```python
# 分檔處理
if current_data_size < target_size:
    # 直接寫入
    csv_writer_instance.add_data_block(data)
else:
    # 需要分檔
    empty_space = target_size - (current_data_size - data_actual_size)
    while current_data_size >= target_size:
        batch = data[:empty_space]
        csv_writer_instance.add_data_block(batch)
        csv_writer_instance.update_filename()
        current_data_size -= target_size
    # 處理剩餘資料
    if pending:
        remaining_data = data[empty_space:]
        csv_writer_instance.add_data_block(remaining_data)
        current_data_size = pending
```

**設計理由**：
- 確保每個 CSV 檔案包含精確的資料量
- 處理跨檔案的資料邊界
- 避免資料遺失或重複

#### 4. 降頻處理與佇列管理（main.py - Version 7.0.0）

```python
# 降頻處理
channels = 3
step = channels * WEB_DOWNSAMPLE_RATIO  # 3 * 50 = 150
downsampled_chunk = []

for i in range(0, len(data), step):
    if i + channels <= len(data):
        downsampled_chunk.extend(data[i : i + channels])

# 放入 Web 佇列
if downsampled_chunk:
    with data_lock:
        web_data_queue.put(downsampled_chunk)
```

**設計理由**：
- 降頻處理：大幅減少前端資料傳輸量和繪圖負擔
- 佇列機制：使用佇列而非大型緩衝區，記憶體使用更穩定
- 原始資料保留：CSV 和 SQL 仍使用原始資料（不降頻），確保資料完整性
        # 限制記憶體使用，保留最近 10000 個資料點
        if len(realtime_data) > 10000:
            realtime_data = realtime_data[-10000:]
    data_counter += len(data)  # 計數器始終更新
```

**設計理由**：
- 避免記憶體無限增長
- 保留最近 10000 個資料點供顯示
- 前端也限制顯示 5000 個點，保持效能
- **智慧優化**：無活躍連線時不更新緩衝區，節省 CPU 和記憶體
- CSV 寫入不受影響，確保資料不遺失

#### 5. 佇列管理（prowavedaq.py）

```python
# 佇列滿時處理
try:
    self.data_queue.put_nowait(processed_data)
except queue.Full:
    # 移除最舊的資料
    try:
        self.data_queue.get_nowait()
        self.data_queue.put_nowait(processed_data)
    except queue.Empty:
        pass
```

**設計理由**：
- 避免佇列阻塞
- 資料過快時，丟棄最舊的資料（FIFO）
- 確保最新資料優先處理

---

## 運作流程

### 系統啟動流程

```
1. 執行 main.py
   │
   ├─→ 建立 Flask 應用程式
   │
   ├─→ 初始化全域狀態變數
   │   - realtime_data = []
   │   - is_collecting = False
   │   - data_counter = 0
   │
   ├─→ 啟動 Flask Thread（背景）
   │   - 監聽 0.0.0.0:8080
   │   - 處理 HTTP 請求
   │
   └─→ 主執行緒進入等待迴圈
       - while True: time.sleep(1)
       - 等待 Ctrl+C 中斷
```

### 資料收集啟動流程（使用者點擊「開始讀取」）

```
1. 前端發送 POST /start
   │
   ├─→ 驗證 Label
   │
   ├─→ 重置狀態
   │   - 清空 realtime_data
   │   - 重置計數器
   │
   ├─→ 載入設定檔
   │   - 讀取 csv.ini（CSV 分檔間隔）
   │   - 讀取 sql.ini（SQL 上傳間隔）
   │   - 讀取 ProWaveDAQ.ini（設備設定）
   │
   ├─→ 初始化 DAQ
   │   - 建立 ProWaveDAQ 實例
   │   - 建立 Modbus 連線
   │   - 設定取樣率
   │
   ├─→ 計算目標大小
   │   - target_size = second × sample_rate × channels
   │
   ├─→ 建立輸出目錄
   │   - output/ProWaveDAQ/{timestamp}_{label}/
   │
   ├─→ 初始化 CSV Writer（如果啟用）
   │   - 建立第一個 CSV 檔案
   │
   ├─→ 初始化 SQL Uploader（如果啟用）
   │   - 建立暫存檔案目錄
   │   - 建立第一個暫存檔案
   │
   ├─→ 啟動 Collection Thread
   │   - is_collecting = True
   │   - collection_loop() 開始執行
   │
   ├─→ 啟動 CSV Writer Thread（如果啟用 CSV）
   │   - csv_writer_loop() 開始執行
   │
   ├─→ 啟動 SQL Writer Thread（如果啟用 SQL）
   │   - sql_writer_loop() 開始執行
   │
   ├─→ 啟動 DAQ Reading Thread
   │   - daq_instance.start_reading()
   │   - _read_loop() 開始執行
   │
   └─→ 返回成功回應
       - 前端收到回應，開始更新圖表
```

### 資料收集運作流程（持續執行）

```
DAQ Reading Thread (_read_loop):
├─→ 讀取資料長度（位址 0x02）
├─→ 根據長度讀取資料
├─→ 轉換資料格式（16位元 → 浮點數）
├─→ 放入資料佇列
└─→ 重複執行

Collection Thread (collection_loop):
├─→ 從 DAQ 佇列取得資料
├─→ 更新即時資料緩衝區（供前端顯示）
├─→ 將資料放入 CSV 佇列（如果啟用 CSV）
├─→ 將資料放入 SQL 佇列（如果啟用 SQL）
└─→ 重複執行

CSV Writer Thread (csv_writer_loop):
├─→ 從 CSV 佇列取得資料
├─→ 處理 CSV 寫入（包含分檔邏輯）
└─→ 重複執行

SQL Writer Thread (sql_writer_loop):
├─→ 從 SQL 佇列取得資料
├─→ 寫入 SQL 暫存檔案
├─→ 定時上傳（如果達到目標大小）
└─→ 重複執行

Flask Thread:
├─→ 處理 HTTP 請求
├─→ /data: 返回即時資料
├─→ 其他路由: 處理對應功能
└─→ 持續運作

前端 JavaScript:
├─→ 每 200ms 呼叫 /data API
├─→ 更新 Chart.js 圖表
└─→ 顯示狀態資訊
```

### 資料收集停止流程（使用者點擊「停止讀取」）

```
1. 前端發送 POST /stop
   │
   ├─→ 設定 is_collecting = False
   │   - Collection Thread 結束迴圈
   │
   ├─→ 停止 DAQ 讀取
   │   - daq_instance.stop_reading()
   │   - 設定 reading = False
   │   - Reading Thread 結束迴圈
   │   - 關閉 Modbus 連線
   │
   ├─→ 等待所有佇列處理完成
   │   - csv_data_queue.join()（如果啟用 CSV）
   │   - sql_data_queue.join()（如果啟用 SQL）
   │
   ├─→ 關閉 CSV Writer（如果啟用）
   │   - csv_writer_instance.close()
   │   - 關閉當前檔案
   │
   ├─→ 關閉 SQL Uploader（如果啟用）
   │   - sql_uploader_instance.close()
   │   - 上傳剩餘暫存檔案
   │
   └─→ 返回成功回應
       - 前端停止圖表更新
       - 更新 UI 狀態
```

### 系統關閉流程（Ctrl+C）

```
1. 使用者按 Ctrl+C
   │
   ├─→ 捕獲 KeyboardInterrupt
   │
   ├─→ 檢查是否在收集中
   │   │
   │   ├─→ 如果是：執行停止流程
   │   │   - is_collecting = False
   │   │   - 停止 DAQ
   │   │   - 等待所有佇列處理完成
   │   │   - 關閉 CSV Writer（如果啟用）
   │   │   - 關閉 SQL Uploader（如果啟用）
   │   │
   │   └─→ 如果不是：直接關閉
   │
   └─→ 輸出關閉訊息
       - Flask Thread 自動終止（daemon=True）
       - 程式結束
```

---

## 錯誤處理與例外狀況

### 連線錯誤處理

1. **Modbus 連線中斷**
   - 偵測到連線中斷時，自動嘗試重新連線
   - 最多嘗試 5 次
   - 連續失敗 5 次後停止讀取

2. **讀取錯誤**
   - 讀取失敗時，錯誤計數器遞增
   - 連續錯誤 5 次後停止讀取
   - 輸出錯誤訊息到終端機

### 資料處理錯誤

1. **佇列滿載**
   - 自動移除最舊的資料
   - 確保最新資料優先處理

2. **CSV 寫入錯誤**
   - 捕獲例外並輸出錯誤訊息
   - 不影響資料收集繼續進行

### 前端錯誤處理

1. **API 請求失敗**
   - 顯示錯誤訊息
   - 不中斷圖表更新（會繼續嘗試）

2. **資料格式錯誤**
   - 檢查資料是否存在
   - 驗證資料長度

---

## 效能考量

### 記憶體使用

- **即時資料緩衝區**：最多 10000 個點（約 80 KB）
- **DAQ 資料佇列**：最多 1000 筆（約 1 MB）
- **前端圖表資料**：最多 5000 個點（約 40 KB）

### CPU 使用

- **資料讀取**：非阻塞式，避免 CPU 過載
- **資料處理**：短暫休息（10ms），避免忙等待
- **圖表更新**：200ms 間隔，平衡即時性和效能

### 磁碟 I/O

- **CSV 寫入**：每次寫入後立即 `flush()`，確保資料不遺失
- **檔案分檔**：避免單一檔案過大

---

## 擴展與自訂

### 修改通道數

目前系統固定為 3 通道，如需修改：

1. **prowavedaq.py**：修改資料處理邏輯
2. **csv_writer.py**：修改 `__init__` 和標題行
3. **main.py**：修改 `channels = 3` 為變數
4. **index.html**：修改 Chart.js 資料集數量

### 修改取樣率

在 `API/ProWaveDAQ.ini` 中修改 `sampleRate` 參數即可。

### 修改分檔間隔

在 `API/csv.ini` 的 `[DumpUnit]` 區段中修改 `second` 參數即可。

### 修改 SQL 上傳間隔

在 `API/sql.ini` 的 `[DumpUnit]` 區段中修改 `second` 參數即可。

### 新增功能

1. **新增 API 路由**：在 `main.py` 中新增 `@app.route()`
2. **新增前端頁面**：在 `templates/` 中新增 HTML
3. **新增資料處理**：在 `collection_loop()` 中新增邏輯

---

## 總結

本系統是一個完整的即時資料採集與可視化平台，主要特點：

1. **模組化設計**：各模組職責清晰，易於維護
2. **執行緒安全**：使用鎖定和佇列確保資料一致性
3. **記憶體管理**：限制緩衝區大小，避免記憶體過載
4. **錯誤處理**：完善的錯誤處理機制，提高穩定性
5. **Web 介面**：提供友善的使用者介面，無需終端機操作
6. **自動分檔**：根據時間間隔自動分檔儲存，便於資料管理

系統已針對高頻率資料採集進行優化，能夠穩定處理每秒 23,436 個資料點的資料流，並在瀏覽器中即時顯示。

---

**最後更新**：2025年12月22日
**文件版本**：8.0.2
**作者**：王建葦